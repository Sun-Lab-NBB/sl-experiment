"""This module provides classes that abstract working with Sun lab's Mesoscope-VR system to acquire training or
experiment data or maintain the system modules. Primarily, this includes the runtime management classes
(highest level of internal data acquisition and processing API) and specialized runtime logic functions
(user-facing external API functions).
"""

import os
import copy
import json
import shutil as sh
from pathlib import Path
import tempfile

from tqdm import tqdm
import numpy as np
from numpy.typing import NDArray
from ataraxis_time import PrecisionTimer
from sl_shared_assets import (
    SessionData,
    MesoscopePositions,
    ProjectConfiguration,
    RunTrainingDescriptor,
    LickTrainingDescriptor,
    MesoscopeHardwareState,
    MesoscopeExperimentDescriptor,
    MesoscopeExperimentConfiguration,
)
from ataraxis_base_utilities import LogLevel, console
from ataraxis_data_structures import DataLogger, LogPackage, SharedMemoryArray
from ataraxis_time.time_helpers import convert_time, get_timestamp
from ataraxis_communication_interface import MQTTCommunication, MicroControllerInterface

from .tools import MesoscopeData, KeyboardListener, get_system_configuration
from .visualizers import BehaviorVisualizer
from .binding_classes import ZaberMotors, VideoSystems, MicroControllerInterfaces
from ..shared_components import WaterSheet, SurgerySheet, BreakInterface, ValveInterface, write_version_data
from .data_preprocessing import preprocess_session_data


class _MesoscopeExperiment:
    """The base class for all mesoscope experiment runtimes.

    This class provides methods for conducting experiments using the Mesoscope-VR system. It abstracts most
    low-level interactions with the VR system and the mesoscope via a simple high-level state API.

    Notes:
        Calling this initializer only instantiates a minimal subset of all Mesoscope-VR assets. Use the start() method
        before issuing other commands to properly initialize all required runtime assets and remote processes.

        This class statically reserves the id code '1' to label its log entries. Make sure no other Ataraxis class, such
        as MicroControllerInterface or VideoSystem, uses this id code.

    Args:
        experiment_configuration: An initialized MesoscopeExperimentConfiguration instance that specifies experiment
            configuration and runtime sequence.
        session_data: An initialized SessionData instance used to control the flow of data during acquisition and
            preprocessing. Each instance is initialized for the specific project, animal, and session combination for
            which the data is acquired.
        session_descriptor: A partially initialized MesoscopeExperimentDescriptor instance. This instance is used to
            store session-specific information in a human-readable format.

    Attributes:
        _state_map: Maps the integer state-codes used to represent VR system states to human-readable string-names.
        _started: Tracks whether the VR system and experiment runtime are currently running.
        descriptor: Stores the session descriptor instance of the managed session.
        _experiment_configuration: Stores the MesoscopeExperimentConfiguration instance of the managed session.
        _session_data: Stores the SessionData instance of the managed session.
        _mesoscope_data: Stores the MesoscopeData instance of the managed session.
        _vr_state: Stores the current state of the VR system. The MesoscopeExperiment updates this value whenever it is
            instructed to change the VR system state.
        _experiment_state: Stores the user-defined experiment state. Experiment states are defined by the user and
            are expected to have unique meaning for each project and, potentially, experiment.
        _source_id: Stores the unique identifier code for this class instance. The identifier is used to mark log
            entries made by this class instance and has to be unique across all sources that log data at the same time,
            such as MicroControllerInterfaces and VideoSystems.
        _timestamp_timer: A PrecisionTimer instance used to timestamp log entries generated by the class instance.
        _logger: A DataLogger instance that collects behavior log data from all sources: microcontrollers, video
            cameras, and the MesoscopeExperiment instance.
        _microcontrollers: Stores the MicroControllerInterfaces instance that interfaces with all MicroController
            devices used during runtime.
        _cameras: Stores the VideoSystems instance that interfaces with video systems (cameras) used during
            runtime.
        _zaber_motors: Stores the ZaberMotors class instance that interfaces with HeadBar, LickPort, and Wheel motors.
    """

    # Maps integer VR state codes to human-readable string-names.
    _state_map: dict[int, str] = {0: "Idle", 1: "Rest", 2: "Run"}

    def __init__(
        self,
        experiment_configuration: MesoscopeExperimentConfiguration,
        session_data: SessionData,
        session_descriptor: MesoscopeExperimentDescriptor,
    ) -> None:
        # Creates the _started flag first to avoid leaks if the initialization method fails.
        self._started: bool = False

        # Caches SessionDescriptor and MesoscopeExperimentConfiguration instances to class attributes.
        self.descriptor: MesoscopeExperimentDescriptor = session_descriptor
        self._experiment_configuration: MesoscopeExperimentConfiguration = experiment_configuration

        # Caches the descriptor to disk. Primarily, this is required for preprocessing the data if the session runtime
        # terminates unexpectedly.
        self.descriptor.to_yaml(file_path=Path(session_data.raw_data.session_descriptor_path))

        # Saves SessionData to class attribute and uses it to initialize the MesoscopeData instance. MesoscopeData works
        # similar to SessionData, but only stores the paths used by the Mesoscope-VR system while managing the session's
        # data acquisition and preprocessing. These paths only exist on the VRPC filesystem.
        self._session_data: SessionData = session_data
        self._mesoscope_data: MesoscopeData = MesoscopeData(session_data)

        # Defines other flags used during runtime:
        # VR and Experiment states are initialized to 0 by default.
        self._vr_state: int = 0
        self._experiment_state: int = 0
        self._source_id: np.uint8 = np.uint8(1)  # Reserves source ID code 1 for this class
        self._timestamp_timer: PrecisionTimer = PrecisionTimer("us")  # A timer used to timestamp log entries

        # Initializes the DataLogger instance used to log data from all microcontrollers, camera frame savers, and this
        # class instance.
        self._logger: DataLogger = DataLogger(
            output_directory=Path(session_data.raw_data.raw_data_path),
            instance_name="behavior",  # Creates behavior_log subfolder under raw_data
            sleep_timer=0,
            exist_ok=True,
            process_count=1,
            thread_count=10,
        )

        # Initializes the binding class for all MicroController Interfaces.
        self._microcontrollers: MicroControllerInterfaces = MicroControllerInterfaces(data_logger=self._logger)

        # Instantiates an MQTTCommunication instance to directly communicate with Unity. Currently, this is used
        # exclusively to verify that the Unity is running and to collect the sequence of VR wall cues used by the task.
        # MicroController instances that communicate with Unity do it through their internal MQTTCommunication class
        # instances.
        monitored_topics = ("CueSequence/",)
        self._unity: MQTTCommunication = MQTTCommunication(monitored_topics=monitored_topics)

        # Initializes the binding class for all VideoSystems.
        self._cameras: VideoSystems = VideoSystems(
            data_logger=self._logger,
            output_directory=Path(self._session_data.raw_data.camera_data_path),
        )

        # While we can connect to ports managed by ZaberLauncher, ZaberLauncher cannot connect to ports managed via
        # software. Therefore, we have to make sure ZaberLauncher is running before connecting to motors.
        message = (
            "Preparing to connect to all Zaber motor controllers. Make sure that ZaberLauncher app is running before "
            "proceeding further. If ZaberLauncher is not running, you WILL NOT be able to manually control Zaber motor "
            "positions until you reset the runtime."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        self._zaber_motors: ZaberMotors = ZaberMotors(
            zaber_positions_path=self._mesoscope_data.vrpc_persistent_data.zaber_positions_path
        )

        # Extra step to force the user to initialize the Unity game engine. Initializing unity sometimes interferes with
        # other sl-experiment components, mostly the USB cameras.
        message = (
            "This runtime is designed to use Unity game engine to interface with the virtual task environment. Make "
            "sure that the experiment's Unity project is loaded and configured before proceeding further. Loading the "
            "Unity project while this runtime is ongoing may interfere with some hardware modules, causing the runtime "
            "to crash with no possibility of recovery. DO NOT arm the Unity environment until instructed to do so by "
            "this runtime."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

    def start(self) -> None:
        """Initializes and configures all assets used during the experiment.

        This internal method establishes the communication with the microcontrollers, data logger cores, and video
        system processes. It also requests the cue sequence from Unity game engine and starts mesoscope frame
        acquisition process.

        Notes:
            This method will not run unless the host PC has access to the necessary number of logical CPU cores
            and other required hardware resources (GPU for video encoding, etc.). This prevents using the class on
            machines that are unlikely to sustain the runtime requirements.

            As part of its runtime, this method will attempt to set all Zaber motors to the positions optimal for
            mesoscope frame acquisition. Exercise caution and always monitor the system when it is running this method,
            as unexpected motor behavior can damage the mesoscope or harm the animal.

        Raises:
            RuntimeError: If the host PC does not have enough logical CPU cores available.
        """
        # Prevents (re) starting an already started VR process.
        if self._started:
            return

        # 3 cores for microcontrollers, 1 core for the data logger, 6 cores for the current video_system
        # configuration (3 producers, 3 consumer), 1 core for the central process calling this method, 1 core for
        # keyboard monitor. 12 cores total. Note, the system may use additional cores if they are requested from various
        # C / C++ extensions used by our source code.
        cpu_count = os.cpu_count()
        if cpu_count is None or not cpu_count >= 12:
            message = (
                f"Unable to start the Mesoscope-VR experiment runtime. The host PC must have at least 12 logical CPU "
                f"cores available for this runtime to work as expected, but only {cpu_count} cores are "
                f"available."
            )
            console.error(message=message, error=RuntimeError)

        message = "Initializing experiment runtime..."
        console.echo(message=message, level=LogLevel.INFO)

        # Starts the data logger
        self._logger.start()

        # Generates and logs the onset timestamp for the VR system as a whole. The MesoscopeExperiment class logs
        # changes to VR and Experiment state during runtime, so it needs to have the onset stamp, just like all other
        # classes that generate data logs.

        # Constructs the timezone-aware stamp using UTC time. This creates a reference point for all later delta time
        # readouts. The time is returned as an array of bytes.
        onset: NDArray[np.uint8] = get_timestamp(as_bytes=True)  # type: ignore
        self._timestamp_timer.reset()  # Immediately resets the timer to make it as close as possible to the onset time

        # Logs the onset timestamp. All further timestamps will be treated as integer time deltas (in microseconds)
        # relative to the onset timestamp. Note, ID of 1 is used to mark the main experiment system.
        package = LogPackage(
            source_id=self._source_id, time_stamp=np.uint64(0), serialized_data=onset
        )  # Packages the id, timestamp, and data.
        self._logger.input_queue.put(package)

        message = "DataLogger: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Starts the face camera. This starts frame acquisition and displays acquired frames to the user. However,
        # frame saving is disabled at this time. Body cameras are also disabled. This is intentional, as at this point
        # we want to minimize the number of active processes. This is helpful if this method is called while the
        # previous session is still running its data preprocessing pipeline and needs as many free cores as possible.
        self._cameras.start_face_camera()

        # Determines whether to carry out the Zaber motor positioning sequence.
        message = (
            f"Do you want to carry out the Zaber motor preparation sequence for this animal? Most runtimes require "
            f"this step to work as expected. Only enter 'no' if you are restarting a runtime that has already carried "
            f"out the motor positioning, but failed at a later stage."
        )
        console.echo(message=message, level=LogLevel.INFO)
        while True:
            answer = input("Enter 'yes' or 'no': ")

            if answer.lower() == "yes":
                move_zaber = True
                break

            elif answer.lower() == "no":
                move_zaber = False
                break

        if move_zaber:
            # Initializes the Zaber positioning sequence. This relies heavily on user feedback to confirm that it is
            # safe to proceed with motor movements.
            message = (
                "Preparing to move Zaber motors into mounting position. Remove the mesoscope objective, swivel out the "
                "VR screens, and make sure the animal is NOT mounted on the rig. Failure to fulfill these steps may "
                "DAMAGE the mesoscope and / or HARM the animal."
            )
            console.echo(message=message, level=LogLevel.WARNING)
            input("Enter anything to continue: ")

            # Homes all motors in-parallel. The homing trajectories for the motors as they are used now should not
            # intersect with each other, so it is safe to move both assemblies at the same time.
            self._zaber_motors.prepare_motors()

            # Sets the motors into the mounting position. The HeadBar and Wheel are either restored to the previous
            # session's position or are set to the default mounting position stored in non-volatile memory. The
            # LickPort is moved to a position optimized for putting the animal on the VR rig.
            self._zaber_motors.mount_position()

            message = "Motor Positioning: Complete."
            console.echo(message=message, level=LogLevel.SUCCESS)

            # Gives user time to mount the animal and requires confirmation before proceeding further.
            message = (
                "Preparing to move the motors into the imaging position. Mount the animal onto the VR rig and install "
                "the mesoscope objetive. DO NOT adjust any motors manually at this time, as all changes to all motors "
                "will be reset by moving them to the imaging position. Keep the mesoscope objective away from the "
                "animal's head."
            )
            console.echo(message=message, level=LogLevel.WARNING)
            input("Enter anything to continue: ")

            # Primarily, this restores the LickPort to the previous session's position or default parking position. The
            # HeadBar and Wheel should not move, as they are already 'restored'. However, if the user did move them
            # manually, they too will be restored to default positions.
            self._zaber_motors.restore_position()

            message = "Motor Positioning: Complete."
            console.echo(message=message, level=LogLevel.SUCCESS)

        # If previous session's mesoscope positions were saved, loads the objective coordinates and uses them to
        # augment the message to the user.
        if Path(self._mesoscope_data.vrpc_persistent_data.mesoscope_positions_path).exists():
            previous_positions: MesoscopePositions = MesoscopePositions.from_yaml(  # type: ignore
                file_path=Path(self._mesoscope_data.vrpc_persistent_data.mesoscope_positions_path)
            )
            # Gives user time to mount the animal and requires confirmation before proceeding further.
            message = (
                f"If necessary, adjust all Zaber motor positions and position the mesoscope objective above the "
                f"imaging field. Previous mesoscope coordinates were: x={previous_positions.mesoscope_x}, "
                f"y={previous_positions.mesoscope_y}, roll={previous_positions.mesoscope_roll}, "
                f"z={previous_positions.mesoscope_z}, fast_z={previous_positions.mesoscope_fast_z}, "
                f"tip={previous_positions.mesoscope_tip}, tilt={previous_positions.mesoscope_tilt}. Do NOT start the "
                f"Mesoscope or Unity game engine at this time. This is done at a later manual checkpoint."
            )
        else:
            message = (
                "If necessary, adjust all Zaber motor positions and position the mesoscope objective above the imaging "
                "field. Do NOT start the Mesoscope or Unity game engine at this time. This is done at a later manual "
                "checkpoint."
            )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Forces the user to create the dot-alignment and cranial window screenshot on the ScanImage PC before
        # continuing.
        screenshots = [
            screenshot for screenshot in Path(self._mesoscope_data.scanimagepc_data.meso_data_path).glob("*.png")
        ]
        while len(screenshots) != 1:
            message = (
                f"Unable to retrieve the screenshot of the cranial window and the dot-alignment from the "
                f"ScanImage PC. Specifically, expected a single .png file to be stored in the root mesoscope "
                f"data folder of the ScanImagePC, but instead found {len(screenshots)} candidates. Generate a "
                f"single screenshot of the cranial window and the dot-alignment on the ScanImagePC by "
                f"positioning them side-by-side and using 'Win + PrtSc' combination. Remove any extra "
                f"screenshots stored in the folder before proceeding."
            )
            console.echo(message=message, level=LogLevel.WARNING)
            input("Enter anything to continue: ")
            screenshots = [
                screenshot for screenshot in Path(self._mesoscope_data.scanimagepc_data.meso_data_path).glob("*.png")
            ]

        # Transfers the screenshot to the mesoscope_frames folder of the session's raw_data folder
        screenshot_path = Path(self._session_data.raw_data.window_screenshot_path)
        source_path: Path = screenshots[0]
        sh.move(source_path, screenshot_path)  # Moves the screenshot from the ScanImagePC to the VRPC

        # Generates a snapshot of all zaber motor positions. This serves as an early checkpoint in case the runtime has
        # to be aborted in a non-graceful way (without running the stop() sequence). This way, next runtime will restart
        # with the calibrated zaber positions.
        zaber_positions = self._zaber_motors.generate_position_snapshot()

        # Saves the newly generated file both to the persistent folder and to the session folder. Note, saving to the
        # persistent data directory automatically overwrites any existing positions file.
        zaber_positions.to_yaml(file_path=Path(self._mesoscope_data.vrpc_persistent_data.zaber_positions_path))
        zaber_positions.to_yaml(file_path=Path(self._session_data.raw_data.zaber_positions_path))

        message = "Zaber motor positions: Saved."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Generates a snapshot of the runtime hardware configuration. In turn, this data is used to parse the .npz log
        # files during processing.
        hardware_state = MesoscopeHardwareState(
            cue_map=self._experiment_configuration.cue_map,
            cm_per_pulse=float(self._microcontrollers.wheel_encoder.cm_per_pulse),
            maximum_break_strength=float(self._microcontrollers.wheel_break.maximum_break_strength),
            minimum_break_strength=float(self._microcontrollers.wheel_break.minimum_break_strength),
            lick_threshold=int(self._microcontrollers.lick.lick_threshold),
            valve_scale_coefficient=float(self._microcontrollers.valve.scale_coefficient),
            valve_nonlinearity_exponent=float(self._microcontrollers.valve.nonlinearity_exponent),
            torque_per_adc_unit=float(self._microcontrollers.torque.torque_per_adc_unit),
            screens_initially_on=self._microcontrollers.screens.initially_on,
            recorded_mesoscope_ttl=True,
        )
        hardware_state.to_yaml(Path(self._session_data.raw_data.hardware_state_path))
        message = "Mesoscope-VR hardware state snapshot: Generated."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Saves the MesoscopeExperimentConfiguration instance to the session folder.
        self._experiment_configuration.to_yaml(Path(self._session_data.raw_data.experiment_configuration_path))
        message = "Experiment configuration snapshot: Generated."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Enables body cameras. Starts frame saving for all cameras
        self._cameras.start_body_cameras()
        self._cameras.save_face_camera_frames()
        self._cameras.save_body_camera_frames()

        # Establishes a direct communication with Unity over MQTT. This is in addition to some ModuleInterfaces using
        # their own communication channels.
        self._unity.connect()

        # Starts all microcontroller interfaces
        self._microcontrollers.start()

        # This checkpoint is moved here to avoid potential issues introduced by resetting the microcontrollers while
        # the mesoscope is monitoring for trigger cues. The rest procedure sometimes generates a TTL 'blip', which may
        # inadvertently interfere with mesoscope frame acquisition triggers.
        message = (
            f"Run all mesoscope and Unity preparation procedures before continuing. This is the last manual "
            f"checkpoint, after this message the runtime control function will begin the experiment."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Starts monitoring the sensors used during all VR states. Currently, this is the lick sensor state and
        # the mesoscope frame ttl module state.
        self._microcontrollers.enable_mesoscope_frame_monitoring()
        self._microcontrollers.enable_lick_monitoring()

        # Sets the rest of the subsystems to use the IDLE state.
        self.idle()

        # Starts mesoscope frame acquisition. This also verifies that the mesoscope responds to triggers and
        # actually starts acquiring frames using the _mesoscope_frame interface above.
        self._start_mesoscope()

        # Queries the task cue (segment) sequence from Unity. This also acts as a check for whether Unity is
        # running and is configured appropriately. The extracted sequence data is logged as a sequence of byte
        # values.
        cue_sequence = self._get_cue_sequence()
        package = LogPackage(
            source_id=self._source_id,
            time_stamp=np.uint64(self._timestamp_timer.elapsed),
            serialized_data=cue_sequence,
        )
        self._logger.input_queue.put(package)

        message = "Unity virtual task: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Marks the beginning of the experiment runtime by logging 0-0 state message.
        self._change_vr_state(new_state=0)
        self.change_experiment_state(new_state=0)

        # The setup procedure is complete.
        self._started = True

        message = "Experiment: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def stop(self) -> None:
        """Stops and terminates all Mesoscope-VR components and ends the experiment runtime.

        This method achieves two main purposes. First, it releases the hardware resources used during the experiment
        runtime by various system components. Second, it pulls all collected data to the VRPC and runs the preprocessing
        pipeline on the data to prepare it for long-term storage and further processing.
        """

        # Prevents stopping an already stopped process.
        if not self._started:
            return

        message = "Terminating experiment runtime..."
        console.echo(message=message, level=LogLevel.INFO)

        # Resets the _started tracker
        self._started = False

        # Switches the system into the IDLE state. Since IDLE state has most modules set to stop-friendly states,
        # this is used as a shortcut to prepare the VR system for shutdown.
        self.idle()

        # Stops mesoscope frame acquisition.
        self._microcontrollers.stop_mesoscope()
        self._timestamp_timer.reset()  # Resets the timestamp timer. It is now co-opted to enforce the shutdown delay
        message = "Mesoscope frame acquisition stop command: Sent."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Stops all cameras.
        self._cameras.stop()

        # Manually stops hardware modules not stopped by the REST state. This excludes mesoscope frame monitoring, which
        # is stopped separately after the 5-second delay (see below).
        self._microcontrollers.disable_lick_monitoring()
        self._microcontrollers.disable_torque_monitoring()

        # Delays for 5 seconds to give mesoscope time to stop acquiring frames. Primarily, this ensures that all
        # mesoscope frames have recorded acquisition timestamps. This implementation times the delay relative to the
        # mesoscope shutdown command and allows running other shutdown procedures in-parallel with the mesoscope
        # shutdown processing.
        while self._timestamp_timer.elapsed < 5000000:
            continue

        # Stops mesoscope frame monitoring. At this point, the mesoscope should have stopped acquiring frames.
        self._microcontrollers.disable_mesoscope_frame_monitoring()

        # Stops all microcontroller interfaces
        self._microcontrollers.stop()

        # 0-state is used to mark the start and end of the experiment runtime
        self._change_vr_state(new_state=0)
        self.change_experiment_state(new_state=0)

        # Stops the data logger instance
        self._logger.stop()

        message = "Data Logger: Stopped."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Updates the contents of the pregenerated descriptor file and dumps it as a .yaml into the root raw_data
        # session directory. This needs to be done after the microcontrollers and loggers have been stopped to ensure
        # that the reported dispensed_water_volume_ul is accurate.
        delivered_water = self._microcontrollers.total_delivered_volume

        # Overwrites the delivered water volume with the volume recorded over the runtime.
        self.descriptor.dispensed_water_volume_ml = round(delivered_water / 1000, ndigits=3)  # Converts from uL to ml
        self.descriptor.incomplete = False  # If the runtime reaches this point, the session is likely complete.

        # Dumps the updated descriptor as a .yaml, so that the user can edit it with user-generated data.
        self.descriptor.to_yaml(file_path=Path(self._session_data.raw_data.session_descriptor_path))

        # Generates a precursor MesoscopePositions file and dumps it into the session folder.
        # If a previous set of mesoscope position coordinates is available, overwrites the 'default' mesoscope
        # coordinates with the positions loaded from the persistent storage file. This way, if the user used the same
        # coordinates as last time, they do not need to update the mesoscope coordinates when manually editing the
        # descriptor.
        force_mesoscope_positions_update: bool = False
        if Path(self._mesoscope_data.vrpc_persistent_data.mesoscope_positions_path).exists():
            sh.copy(
                self._mesoscope_data.vrpc_persistent_data.mesoscope_positions_path,
                self._session_data.raw_data.mesoscope_positions_path,
            )
            # Loads the previous position data into memory
            previous_mesoscope_positions: MesoscopePositions = MesoscopePositions.from_yaml(  # type: ignore
                file_path=self._session_data.raw_data.mesoscope_positions_path
            )
        else:
            # 'Default' precursor de-novo creation. We have a checker (see below) to ensure the user modifies the
            # precursor.
            previous_mesoscope_positions = MesoscopePositions()
            previous_mesoscope_positions.to_yaml(file_path=Path(self._session_data.raw_data.mesoscope_positions_path))

            # If this runtime generates the precursor file, it automatically forces the user to update the default
            # precursor values.
            force_mesoscope_positions_update = True

        message = "Mesoscope objective position snapshot: Created."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Generates the snapshot of the current Zaber motor positions and saves them as a .yaml file. This has
        # to be done before Zaber motors are reset back to parking position.
        zaber_positions = self._zaber_motors.generate_position_snapshot()

        # Saves the newly generated file both to the persistent folder and to the session folder. Note, saving to the
        # persistent data directory automatically overwrites any existing positions file.
        zaber_positions.to_yaml(file_path=Path(self._mesoscope_data.vrpc_persistent_data.zaber_positions_path))
        zaber_positions.to_yaml(file_path=Path(self._session_data.raw_data.zaber_positions_path))

        message = "Zaber motor positions: Saved."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Determines whether to carry out the Zaber motor shutdown sequence.
        message = (
            f"Do you want to carry out the Zaber motor shutdown sequence? This should be done for most runtimes. The "
            f"only reason to skip the shutdown sequence is if you are shutting down the current runtime to immediately "
            f"restart (rerun) it for the same animal. In this case, skipping the shutdown (and setup) of Zaber motors "
            f"allows to keep the animal mounted in the VR rig."
        )
        console.echo(message=message, level=LogLevel.INFO)
        while True:
            answer = input("Enter 'yes' or 'no': ")

            if answer.lower() == "yes":
                move_zaber = True
                break

            elif answer.lower() == "no":
                move_zaber = False
                break

        # Helps with removing the animal from the rig by retracting the lick-port in the Y-axis (moving it away from the
        # animal).
        if move_zaber:
            message = f"Retracting the lick-port away from the animal..."
            console.echo(message=message, level=LogLevel.INFO)

            self._zaber_motors.unmount_position()

            message = "Motor Positioning: Complete."
            console.echo(message=message, level=LogLevel.SUCCESS)

        # Notifies the user that the acquisition is complete.
        console.echo(message=f"Data acquisition: Complete.", level=LogLevel.SUCCESS)

        # Prompts the user to add their notes to the appropriate section of the descriptor file. This has to be done
        # before processing so that the notes are properly transferred to the NAS and server.
        message = (
            f"Open the session descriptor file stored in session's raw_data folder and update it with the notes taken "
            f"during runtime."
        )
        console.echo(message=message, level=LogLevel.INFO)
        input("Enter anything to continue: ")

        # Verifies and blocks in-place until the user updates the session descriptor file with experimenter notes.
        self.descriptor = MesoscopeExperimentDescriptor.from_yaml(  # type: ignore
            file_path=Path(self._session_data.raw_data.session_descriptor_path)
        )
        while "Replace this with your notes." in self.descriptor.experimenter_notes:
            message = (
                "Failed to verify that the session_descriptor.yaml file stored inside the session raw_data directory "
                "has been updated to include experimenter notes. Manually edit the session_descriptor.yaml file and "
                "replace the default text under the 'experimenter_notes' field with the notes taken during the "
                "experiment. Make sure to save the changes to the file by using 'CTRL+S' combination."
            )
            console.echo(message=message, level=LogLevel.ERROR)
            input("Enter anything to continue: ")

            # Reloads the descriptor from disk each time to ensure experimenter notes have been modified.
            self.descriptor = MesoscopeExperimentDescriptor.from_yaml(  # type: ignore
                file_path=Path(self._session_data.raw_data.session_descriptor_path),
            )

        # If the descriptor has passed the verification, backs it up to the animal's persistent directory. This is a
        # feature primarily used during training to restore the training parameters between training sessions of the
        # same type. However, the MesoscopeData resolves the paths to the persistent descriptor files in a way that
        # allows to keep a copy of each supported descriptor without interfering with other descriptor types.
        sh.copy2(
            src=self._session_data.raw_data.session_descriptor_path,
            dst=self._mesoscope_data.vrpc_persistent_data.session_descriptor_path,
        )

        # If this runtime was able to reuse the mesoscope objective position data from a previous session, asks the
        # user whether they have updated the mesoscope positions. If not, then there is no need to update the data
        # inside the .YAML file.
        if not force_mesoscope_positions_update:
            message = (
                f"Do you want to update the mesoscope objective position data stored inside the "
                f"mesoscope_positions.yaml file loaded from the previous session? If you moved the mesoscope objective "
                f"or changed the fast_z, tip or tilt ScanImage parameters, answer 'yes'. If you did not update any "
                f"mesoscope positions, answer 'no'."
            )
            console.echo(message=message, level=LogLevel.INFO)
            while True:
                answer = input("Enter 'yes' or 'no': ")

                if answer.lower() == "yes":
                    force_mesoscope_positions_update = True
                    break

                elif answer.lower() == "no":
                    force_mesoscope_positions_update = False
                    break

        # Forces the user to update the mesoscope positions file with current mesoscope data if the mesoscope positions
        # file is a precursor or the user has indicated that the positions need to be updated.
        if force_mesoscope_positions_update:
            # Reads the current mesoscope positions data cached inside the session's mesoscope_positions.yaml file.
            mesoscope_positions: MesoscopePositions = MesoscopePositions.from_yaml(  # type: ignore
                file_path=Path(self._session_data.raw_data.mesoscope_positions_path),
            )

            # Ensures that the data cached into memory (precursor or previous session data) is at least partially
            # not matching the data currently stored in the file. In other words, ensures that the user has updated the
            # position data.
            while (
                mesoscope_positions.mesoscope_x == previous_mesoscope_positions.mesoscope_x
                and mesoscope_positions.mesoscope_y == previous_mesoscope_positions.mesoscope_y
                and mesoscope_positions.mesoscope_z == previous_mesoscope_positions.mesoscope_z
                and mesoscope_positions.mesoscope_roll == previous_mesoscope_positions.mesoscope_roll
                and mesoscope_positions.mesoscope_fast_z == previous_mesoscope_positions.mesoscope_fast_z
                and mesoscope_positions.mesoscope_tip == previous_mesoscope_positions.mesoscope_tip
                and mesoscope_positions.mesoscope_tilt == previous_mesoscope_positions.mesoscope_tilt
            ):
                message = (
                    "Failed to verify that the mesoscope_positions.yaml file stored inside the session raw_data "
                    "directory has been updated to include the mesoscope objective positions used during runtime. "
                    "Manually edit the mesoscope_positions.yaml file to update the position fields with coordinates "
                    "displayed in ScanImage software and ThorLabs pad. Make sure to save the changes to the file by "
                    "using 'CTRL+S' combination."
                )
                console.echo(message=message, level=LogLevel.ERROR)
                input("Enter anything to continue: ")

                # Reloads the positions file each time to ensure positions have been modified.
                mesoscope_positions: MesoscopePositions = MesoscopePositions.from_yaml(  # type: ignore
                    file_path=Path(self._session_data.raw_data.mesoscope_positions_path),
                )

        # Optionally moves the motors to their parking positions
        if move_zaber:
            message = (
                "Uninstall the mesoscope objective and REMOVE the animal from the VR rig. Failure to do so may DAMAGE "
                "the mesoscope objective and HARM the animal. This is the last manual checkpoint, once you progress "
                "past this point, the Microscope-VR system will reset Zaber motor positions and start data "
                "preprocessing."
            )
            console.echo(message=message, level=LogLevel.WARNING)
            input("Enter anything to continue: ")

            self._zaber_motors.park_position()

        # Disconnects from Zaber motor. This does not change motor positions, but does lock (park) all motors before
        # disconnecting.
        self._zaber_motors.disconnect()

        message = "Zaber motors: Reset."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Preprocesses the session data
        preprocess_session_data(session_data=self._session_data)

        message = "Experiment runtime: Terminated."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def rest(self) -> None:
        """Switches the Mesoscope-VR system to the rest state.

        In the rest state, the break is engaged to prevent the mouse from moving the wheel. The encoder module is
        disabled, and instead the torque sensor is enabled. The VR screens are switched off, cutting off light emission.
        By default, the VR system starts all experimental runtimes using the REST state.

        Notes:
            Rest Mesoscope-VR state is hardcoded as '1'.
        """

        # Prevents changing the VR state if the VR system is already in REST state.
        if self._vr_state == 1:
            return

        # Ensures VR screens are turned OFF
        self._microcontrollers.disable_vr_screens()

        # Engages the break to prevent the mouse from moving the wheel
        self._microcontrollers.enable_break()

        # Temporarily suspends encoder monitoring. Since the wheel is locked, the mouse should not be able to produce
        # meaningful motion data.
        self._microcontrollers.disable_encoder_monitoring()

        # Initiates torque monitoring.The torque can only be accurately measured when the wheel is locked, as it
        # requires a resistance force to trigger the sensor.
        self._microcontrollers.enable_torque_monitoring()

        # Configures the state tracker to reflect the REST state
        self._change_vr_state(1)

    def run(self) -> None:
        """Switches the Mesoscope-VR system to the run state.

        In the run state, the break is disengaged to allow the mouse to freely move the wheel. The encoder module is
        enabled to record and share live running data with Unity, and the torque sensor is disabled. The VR screens are
        switched on to render the VR environment.

        Notes:
            Run Mesoscope-VR state is hardcoded as '2'.
        """

        # Prevents changing the VR state if the VR system is already in RUN state.
        if self._vr_state == 2:
            return

        # Initializes encoder monitoring.
        self._microcontrollers.enable_encoder_monitoring()

        # Disables torque monitoring. To accurately measure torque, the sensor requires a resistance force provided by
        # the break. During running, measuring torque is not very reliable and adds little value compared to the
        # encoder.
        self._microcontrollers.disable_torque_monitoring()

        # Toggles the state of the VR screens ON.
        self._microcontrollers.enable_vr_screens()

        # Disengages the break to allow the mouse to move the wheel
        self._microcontrollers.disable_break()

        # Configures the state tracker to reflect RUN state
        self._change_vr_state(2)

    def idle(self) -> None:
        """Switches the Mesoscope-VR system to the idle state.

        In the idle state, the break is engaged to prevent the animal from moving the wheel and the screens are turned
        off. Both torque and encoder monitoring is disabled. Note, idle state is designed to be used exclusively by the
        sl-experiment library. Specifically, this state is used when the user requests the runtime to be paused for
        any reason.

        Notes:
            Idle Mesoscope-VR state is hardcoded as '0'.
        """

        # If the VR system is already in the idle state, returns without doing anything.
        if self._vr_state == 0:
            return

        # Ensures VR screens are turned OFF to prevent unwanted stimulation due to any active interference with Unity
        # during the idle period.
        self._microcontrollers.disable_vr_screens()

        # Engages the break to prevent the mouse from moving the wheel during the idle period.
        self._microcontrollers.enable_break()

        # Disables torque and encoder monitoring to avoid injecting motion noise while the system is restarting
        self._microcontrollers.disable_encoder_monitoring()
        self._microcontrollers.disable_torque_monitoring()

        # Sets the VR state to 0. This is used to indicate the start and end periods of the runtime and also to mark
        # user-requested runtime stage restarts (resets).
        self._change_vr_state(0)

    def deliver_reward(self, reward_size: float = 5.0) -> None:
        """Uses the solenoid valve to deliver the requested volume of water in microliters.

        This method is used by the experiment runtime logic to allow the experimenter to manually deliver water to the
        animal.
        """
        self._microcontrollers.deliver_reward(volume=reward_size)

    def _get_cue_sequence(self) -> NDArray[np.uint8]:
        """Requests Unity game engine to transmit the sequence of virtual reality track wall cues for the current task.

        This method is used as part of the experimental runtime startup process to both get the sequence of cues and
        verify that the Unity game engine is running and configured correctly.

        Returns:
            The NumPy array that stores the sequence of virtual reality segments as byte (uint8) values.

        Notes:
            This method contains an infinite loop that allows retrying the failed connection. This prevents the runtime
            from aborting unless the user purposefully chooses the hard abort option.

        Raises:
            RuntimeError: If Unity sends a message to an unexpected (different) topic other than "CueSequence/" while
                this method is running. Also, if the user chooses to abort the runtime if the method does not receive a
                response from Unity in 2 seconds.
        """
        # Initializes a second-precise timer to ensure the request is fulfilled within a 2-second timeout
        timeout_timer = PrecisionTimer("s")

        status = False
        outcome = ""
        # The procedure will be repeated until it succeeds or the user manually aborts the loop
        while not status and outcome != "abort":
            # Sends a request for the task cue (corridor) sequence to Unity GIMBL package.
            self._unity.send_data(topic="CueSequenceTrigger/")

            # Waits at most 2 seconds to receive the response
            timeout_timer.reset()
            while timeout_timer.elapsed < 2:
                # If Unity responds with the cue sequence message, attempts to parse the message
                if self._unity.has_data:
                    topic: str
                    payload: bytes
                    topic, payload = self._unity.get_data()  # type: ignore
                    if topic == "CueSequence/":
                        # Extracts the sequence of cues that will be used during task runtime.
                        sequence: NDArray[np.uint8] = np.array(
                            json.loads(payload.decode("utf-8"))["cue_sequence"], dtype=np.uint8
                        )
                        return sequence

                    else:
                        # If the topic is not "CueSequence/", aborts with an error
                        message = (
                            f"Received an unexpected topic {topic} while waiting for Unity to respond to the cue "
                            f"sequence request. Make sure the Unity is not configured to send data to other topics "
                            f"monitored by the MesoscopeExperiment instance until the cue sequence is resolved as part "
                            f"of the start() method runtime."
                        )
                        console.error(message=message, error=RuntimeError)

            # If the loop above is escaped, this is due to not receiving any message from Unity. Raises an error.
            message = (
                f"The MesoscopeExperiment has requested the task Cue Sequence by sending the trigger to the "
                f"'CueSequenceTrigger/' topic and received no response for 2 seconds. It is likely that the Unity game "
                f"engine is not running or is not configured to work with MesoscopeExperiment. Make sure Unity Game "
                f"engine is started and configured before continuing."
            )
            console.echo(message=message, level=LogLevel.ERROR)
            outcome = input("Enter 'abort' to abort with an error. Enter anything else to retry: ").lower()

        message = f"Runtime aborted due to user request."
        console.error(message=message, error=RuntimeError)
        raise RuntimeError(message)  # Fallback to appease mypy, should not be reachable

    def _start_mesoscope(self) -> None:
        """Sends the frame acquisition start TTL pulse to the mesoscope and waits for the frame acquisition to begin.

        This method is used internally to start the mesoscope frame acquisition as part of the experiment startup
        process. It is also used to verify that the mesoscope is available and properly configured to acquire frames
        based on the input triggers.

        Notes:
            This method contains an infinite loop that allows retrying the failed mesoscope acquisition start. This
            prevents the runtime from aborting unless the user purposefully chooses the hard abort option.

        Raises:
            RuntimeError: If the mesoscope does not confirm frame acquisition within 2 seconds after the
                acquisition trigger is sent and the user chooses to abort the runtime.
        """

        # Initializes a second-precise timer to ensure the request is fulfilled within a 2-second timeout
        timeout_timer = PrecisionTimer("s")

        status = False
        outcome = ""
        # The procedure will be repeated until it succeeds or the user manually aborts the loop
        while not status and outcome != "abort":
            # Instructs the mesoscope to begin acquiring frames
            self._microcontrollers.start_mesoscope()

            # Waits at most 2 seconds for the mesoscope to begin sending frame acquisition timestamps to the PC
            timeout_timer.reset()
            while timeout_timer.elapsed < 2:
                # If the mesoscope starts scanning a frame, the method has successfully started the mesoscope frame
                # acquisition.
                if self._microcontrollers.mesoscope_frame_count:
                    message = "Mesoscope frame acquisition: Started."
                    console.echo(message=message, level=LogLevel.SUCCESS)

                    message = "Verifying the acquisition stability by acquiring 200 frames over the next 20 seconds..."
                    console.echo(message=message, level=LogLevel.INFO)

                    timeout_timer.reset()
                    stability_check = True
                    while self._microcontrollers.mesoscope_frame_count < 200:

                        # At ~10 Hz, this should be over in 20 seconds. If the frames are not acquired in 30 seconds,
                        # indicates a runtime error.
                        if timeout_timer.elapsed > 30:
                            stability_check = False
                            break

                    # If the stability check is passed, returns to caller. Otherwise, raises an error.
                    if stability_check:
                        return

            # If the loop above is escaped, this is due to not receiving the mesoscope frame acquisition pulses.
            message = (
                f"The MesoscopeExperiment has requested the mesoscope to start acquiring frames and received no frame "
                f"acquisition trigger for 2 seconds or failed to acquire 200 frames over 30 second. It is likely that "
                f"the mesoscope has not been armed for frame acquisition or that the mesoscope trigger or frame "
                f"timestamp connection is not functional. Make sure the Mesoscope is configured for data acquisition "
                f"before continuing and retry the mesoscope activation."
            )
            console.echo(message=message, level=LogLevel.ERROR)
            outcome = input("Enter 'abort' to abort with an error. Enter anything else to retry: ").lower()

        message = f"Runtime aborted due to user request."
        console.error(message=message, error=RuntimeError)
        raise RuntimeError(message)  # Fallback to appease mypy, should not be reachable

    def _change_vr_state(self, new_state: int) -> None:
        """Updates and logs the new Mesoscope-VR state.

        This method is used internally to timestamp and log VR state (stage) changes, such as transitioning between
        rest and run VR states.

        Args:
            new_state: The byte-code for the newly activated VR state.
        """
        self._vr_state = new_state  # Updates the VR state

        # Logs the VR state update. Uses header-code 1 to indicate that the logged value is the VR state-code.
        log_package = LogPackage(
            source_id=self._source_id,
            time_stamp=np.uint64(self._timestamp_timer.elapsed),
            serialized_data=np.array([1, new_state], dtype=np.uint8),
        )
        self._logger.input_queue.put(log_package)

    def change_experiment_state(self, new_state: int) -> None:
        """Updates and logs the new experiment state.

        Use this method to timestamp and log experiment state (stage) changes, such as transitioning between different
        task goals.

        Args:
            new_state: The integer byte-code for the new experiment state. The code will be serialized as an uint8
                value, so only values between 0 and 255 inclusive are supported.
        """

        # Prevents changing the experiment state if the experiment is already in the desired state.
        if self._experiment_state == new_state:
            return

        self._experiment_state = new_state  # Updates the tracked experiment state value

        # Logs the VR state update. Uses header-code 2 to indicate that the logged value is the experiment state-code.
        log_package = LogPackage(
            source_id=self._source_id,
            time_stamp=np.uint64(self._timestamp_timer.elapsed),
            serialized_data=np.array([2, new_state], dtype=np.uint8),
        )
        self._logger.input_queue.put(log_package)

    @property
    def trackers(self) -> tuple[SharedMemoryArray, SharedMemoryArray, SharedMemoryArray]:
        """Returns the tracker SharedMemoryArrays for (in this order) the LickInterface, ValveInterface, and
        EncoderInterface.

        These arrays should be passed to the BehaviorVisualizer class to monitor the lick, valve and running speed data
        in real time during the experiment session.
        """
        return (
            self._microcontrollers.lick_tracker,
            self._microcontrollers.valve_tracker,
            self._microcontrollers.distance_tracker,
        )


class _BehaviorTraining:
    """The base class for all behavior training runtimes.

    This class provides methods for running the lick and run training sessions using a subset of the Mesoscope-VR
    system. It abstracts most low-level interactions with the VR system and the mesoscope via a simple
    high-level state API.

    Notes:
        Calling this initializer only instantiates a minimal subset of all Mesoscope-VR assets. Use the start() method
        before issuing other commands to properly initialize all required runtime assets and remote processes.

    Args:
        session_data: An initialized SessionData instance used to control the flow of data during acquisition and
            preprocessing. Each instance is initialized for the specific project, animal, and session combination for
            which the data is acquired.
        session_descriptor: A partially initialized LickTrainingDescriptor or RunTrainingDescriptor instance. This
            instance is used to store session-specific information in a human-readable format.

    Attributes:
        _started: Tracks whether the VR system and training runtime are currently running.
        descriptor: Stores the session descriptor instance of the managed session.
        _session_data: Stores the SessionData instance of the managed session.
        _mesoscope_data: Stores the MesoscopeData instance of the managed session.
        _logger: A DataLogger instance that collects behavior log data from all sources: microcontrollers and video
            cameras.
        _microcontrollers: Stores the MicroControllerInterfaces instance that interfaces with all MicroController
            devices used during runtime.
        _cameras: Stores the VideoSystems instance that interfaces with video systems (cameras) used during
            runtime.
        _zaber_motors: Stores the ZaberMotors class instance that interfaces with HeadBar, LickPort, and Wheel motors.
    """

    def __init__(
        self,
        session_data: SessionData,
        session_descriptor: LickTrainingDescriptor | RunTrainingDescriptor,
    ) -> None:
        # Creates the _started flag first to avoid leaks if the initialization method fails.
        self._started: bool = False

        # Caches SessionDescriptor instance to class attribute.
        self.descriptor: LickTrainingDescriptor | RunTrainingDescriptor = session_descriptor

        # Caches the descriptor to disk. Primarily, this is required for preprocessing the data if the session runtime
        # terminates unexpectedly.
        self.descriptor.to_yaml(file_path=Path(session_data.raw_data.session_descriptor_path))

        # Saves SessionData to class attribute and uses it to initialize the MesoscopeData instance. MesoscopeData works
        # similar to SessionData, but only stores the paths used by the Mesoscope-VR system while managing the session's
        # data acquisition and preprocessing. These paths only exist on the VRPC filesystem.
        self._session_data: SessionData = session_data
        self._mesoscope_data: MesoscopeData = MesoscopeData(session_data)

        # Initializes the DataLogger instance used to log data from all microcontrollers, camera frame savers, and this
        # class instance.
        self._logger: DataLogger = DataLogger(
            output_directory=Path(session_data.raw_data.raw_data_path),
            instance_name="behavior",  # Creates behavior_log subfolder under raw_data
            sleep_timer=0,
            exist_ok=True,
            process_count=1,
            thread_count=10,
        )

        # Initializes the binding class for all MicroController Interfaces.
        self._microcontrollers: MicroControllerInterfaces = MicroControllerInterfaces(data_logger=self._logger)

        # Initializes the binding class for all VideoSystems.
        self._cameras: VideoSystems = VideoSystems(
            data_logger=self._logger,
            output_directory=Path(self._session_data.raw_data.camera_data_path),
        )

        # While we can connect to ports managed by ZaberLauncher, ZaberLauncher cannot connect to ports managed via
        # software. Therefore, we have to make sure ZaberLauncher is running before connecting to motors.
        message = (
            "Preparing to connect to all Zaber motor controllers. Make sure that ZaberLauncher app is running before "
            "proceeding further. If ZaberLauncher is not running, you WILL NOT be able to manually control Zaber motor "
            "positions until you reset the runtime."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        self._zaber_motors: ZaberMotors = ZaberMotors(
            zaber_positions_path=self._mesoscope_data.vrpc_persistent_data.zaber_positions_path
        )

    def start(self) -> None:
        """Initializes and configures all assets used during the behavior training.

        This internal method establishes the communication with the microcontrollers, data logger cores, and video
        system processes.

        Notes:
            This method will not run unless the host PC has access to the necessary number of logical CPU cores
            and other required hardware resources (GPU for video encoding, etc.). This prevents using the class on
            machines that are unlikely to sustain the runtime requirements.

            As part of its runtime, this method will attempt to set all Zaber motors to the positions that facilitate
            the training and future experiment sessions. Exercise caution and always monitor the system when it is
            running this method, as unexpected motor behavior can damage the mesoscope or harm the animal.

            Unlike the experiment class start(), this method does not preset the hardware module states during runtime.
            Call the desired training state method to configure the hardware modules appropriately for the chosen
            runtime mode.

        Raises:
            RuntimeError: If the host PC does not have enough logical CPU cores available.
        """
        # Prevents (re) starting an already started VR process.
        if self._started:
            return

        # 3 cores for microcontrollers, 1 core for the data logger, 6 cores for the current video_system
        # configuration (3 producers, 3 consumer), 1 core for the central process calling this method, 1 core for
        # keyboard monitor. 12 cores total. Note, the system may use additional cores if they are requested from various
        # C / C++ extensions used by our source code.
        cpu_count = os.cpu_count()
        if cpu_count is None or not cpu_count >= 12:
            message = (
                f"Unable to start the Mesoscope-VR behavior training runtime. The host PC must have at least 12 "
                f"logical CPU cores available for this runtime to work as expected, but only {cpu_count} cores "
                f"are available."
            )
            console.error(message=message, error=RuntimeError)

        message = "Initializing behavior training runtime..."
        console.echo(message=message, level=LogLevel.INFO)

        # Starts the data logger
        self._logger.start()
        message = "DataLogger: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Starts the face camera. This starts frame acquisition and displays acquired frames to the user. However,
        # frame saving is disabled at this time. Body cameras are also disabled. This is intentional, as at this point
        # we want to minimize the number of active processes. This is helpful if this method is called while the
        # previous session is still running its data preprocessing pipeline and needs as many free cores as possible.
        self._cameras.start_face_camera()

        # TODO Implement this here
        # Determines whether to carry out the Zaber motor positioning sequence.
        message = (
            f"Do you want to carry out the Zaber motor preparation sequence for this animal? Most runtimes require "
            f"this step to work as expected. Only enter 'no' if you are restarting a runtime that has already carried "
            f"out the motor positioning, but failed at a later stage."
        )
        console.echo(message=message, level=LogLevel.INFO)
        while True:
            answer = input("Enter 'yes' or 'no': ")

            if answer.lower() == "yes":
                move_zaber = True
                break

            elif answer.lower() == "no":
                move_zaber = False
                break

        # Initializes the Zaber positioning sequence. This relies heavily on user feedback to confirm that it is safe to
        # proceed with motor movements.
        message = (
            "Preparing to move Zaber motors into mounting position. Remove the mesoscope objective, swivel out the VR "
            "screens, and make sure the animal is NOT mounted on the rig. Failure to fulfill these steps may DAMAGE "
            "the mesoscope and / or HARM the animal."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Homes all motors in-parallel. The homing trajectories for the motors as they are used now should not intersect
        # with each other, so it is safe to move both assemblies at the same time.
        self._zaber_motors.prepare_motors()

        # Sets the motors into the mounting position. The HeadBar and Wheel are either restored to the previous
        # session's position or are set to the default mounting position stored in non-volatile memory. The LickPort is
        # moved to a position optimized for putting the animal on the VR rig.
        self._zaber_motors.mount_position()

        message = "Motor Positioning: Complete."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Gives user time to mount the animal and requires confirmation before proceeding further.
        message = (
            "Preparing to move the motors into the training position. Mount the animal onto the VR rig, but DO NOT "
            "adjust any motors manually at this time, as all changes to all motors will be reset by moving them to the "
            "training position."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Primarily, this restores the LickPort to the previous session's position or default parking position. The
        # HeadBar and Wheel should not move, as they are already 'restored'. However, if the user did move them
        # manually, they too will be restored to default positions.
        self._zaber_motors.restore_position()

        message = "Motor Positioning: Complete."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Instructs the user to adjust all motors and, when ready, starts the training process.
        message = (
            "If necessary, adjust all Zaber motor positions. This is the last manual checkpoint, after this message "
            "the runtime control function will begin the training."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Generates a snapshot of all zaber motor positions. This serves as an early checkpoint in case the runtime has
        # to be aborted in a non-graceful way (without running the stop() sequence). This way, next runtime will restart
        # with the calibrated zaber positions.
        zaber_positions = self._zaber_motors.generate_position_snapshot()

        # Saves the newly generated file both to the persistent folder and to the session folder. Note, saving to the
        # persistent data directory automatically overwrites any existing positions file.
        zaber_positions.to_yaml(file_path=Path(self._mesoscope_data.vrpc_persistent_data.zaber_positions_path))
        zaber_positions.to_yaml(file_path=Path(self._session_data.raw_data.zaber_positions_path))

        message = "Zaber motor positions: Saved."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Enables body cameras. Starts frame saving for all cameras
        self._cameras.start_body_cameras()
        self._cameras.save_face_camera_frames()
        self._cameras.save_body_camera_frames()

        # Initializes communication with the microcontrollers
        self._microcontrollers.start()

        # The setup procedure is complete.
        self._started = True

        message = "Training: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def stop(self) -> None:
        """Stops and terminates all Mesoscope-VR components and ends the behavior training runtime.

        This method achieves two main purposes. First, it releases the hardware resources used during the training
        runtime by various system components. Second, it runs the preprocessing pipeline on the data to prepare it for
        long-term storage and further processing.
        """

        # Prevents stopping an already stopped process.
        if not self._started:
            return

        message = "Terminating behavior training runtime..."
        console.echo(message=message, level=LogLevel.INFO)

        # Resets the _started tracker
        self._started = False

        # Stops all cameras.
        self._cameras.stop()

        # Manually stops all hardware modules before shutting down the microcontrollers
        self._microcontrollers.enable_break()
        self._microcontrollers.disable_lick_monitoring()
        self._microcontrollers.disable_torque_monitoring()
        self._microcontrollers.disable_encoder_monitoring()

        # Stops all microcontroller interfaces
        self._microcontrollers.stop()

        # Stops the data logger instance
        self._logger.stop()

        message = "Data Logger: Stopped."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Updates the contents of the pregenerated descriptor file and dumps it as a .yaml into the root raw_data
        # session directory. This needs to be done after the microcontrollers and loggers have been stopped to ensure
        # that the reported dispensed_water_volume_ul is accurate.
        delivered_water = self._microcontrollers.total_delivered_volume

        # Overwrites the delivered water volume with the volume recorded over the runtime.
        self.descriptor.dispensed_water_volume_ml = round(delivered_water / 1000, ndigits=3)  # Converts from uL to ml
        self.descriptor.incomplete = False  # If the runtime reaches this point, the session is likely complete.

        self.descriptor.to_yaml(file_path=Path(self._session_data.raw_data.session_descriptor_path))

        # Generates the snapshot of the current Zaber motor positions and saves them as a .yaml file. This has
        # to be done before Zaber motors are reset back to parking position.
        zaber_positions = self._zaber_motors.generate_position_snapshot()

        # Saves the newly generated file both to the persistent folder and to the session folder. Note, saving to the
        # persistent data directory automatically overwrites any existing positions file.
        zaber_positions.to_yaml(file_path=Path(self._mesoscope_data.vrpc_persistent_data.zaber_positions_path))
        zaber_positions.to_yaml(file_path=Path(self._session_data.raw_data.zaber_positions_path))

        message = "Zaber motor positions: Saved."
        console.echo(message=message, level=LogLevel.SUCCESS)

        message = f"Retracting the lick-port away from the animal..."
        console.echo(message=message, level=LogLevel.INFO)

        # Helps with removing the animal from the rig by retracting the lick-port in the Y-axis (moving it away from the
        # animal).
        self._zaber_motors.unmount_position()

        message = "Motor Positioning: Complete."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Notifies the user that the data acquisition is complete.
        console.echo(message="Data acquisition: Complete.", level=LogLevel.SUCCESS)

        # Prompts the user to add their notes to the appropriate section of the descriptor file. This has to be done
        # before processing so that the notes are properly transferred to the NAS and server.
        message = (
            f"Open the session descriptor file stored in session's raw_data folder and update it with the notes taken "
            f"during runtime."
        )
        console.echo(message=message, level=LogLevel.INFO)
        input("Enter anything to continue: ")

        # Verifies and blocks in-place until the user has updated the session descriptor file with experimenter notes.
        descriptor: LickTrainingDescriptor | RunTrainingDescriptor = self.descriptor.from_yaml(  # type: ignore
            file_path=Path(self._session_data.raw_data.session_descriptor_path)
        )
        while "Replace this with your notes." in descriptor.experimenter_notes:
            message = (
                "Failed to verify that the session_descriptor.yaml file stored inside the session raw_data directory "
                "has been updated to include experimenter notes. Manually edit the session_descriptor.yaml file and "
                "replace the default text under the 'experimenter_notes' field with the notes taken during the "
                "experiment. Make sure to save the changes to the file by using 'CTRL+S' combination."
            )
            console.echo(message=message, level=LogLevel.ERROR)
            input("Enter anything to continue: ")

            # Reloads the descriptor from disk each time to ensure experimenter notes have been modified.
            descriptor = self.descriptor.from_yaml(  # type: ignore
                file_path=self._session_data.raw_data.session_descriptor_path
            )

        # If the descriptor has passed the verification, backs it up to the animal's persistent directory. This is a
        # feature primarily used during training to restore the training parameters between training sessions of the
        # same type. However, the MesoscopeData resolves the paths to the persistent descriptor files in a way that
        # allows to keep a copy of each supported descriptor without interfering with other descriptor types.
        sh.copy2(
            src=self._session_data.raw_data.session_descriptor_path,
            dst=self._mesoscope_data.vrpc_persistent_data.session_descriptor_path,
        )

        # Instructs the user to remove the animal from the VR rig.
        message = (
            "REMOVE the animal from the VR rig. Failure to do so may DAMAGE the mesoscope and HARM the animal. "
            "This is the last manual checkpoint, once you progress past this point, the Microscope-VR system will "
            "reset Zaber motor positions and start data preprocessing."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Parks and disconnects from all Zaber motors.
        self._zaber_motors.park_position()
        self._zaber_motors.disconnect()

        message = "Zaber motors: Reset."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Preprocesses the session data
        preprocess_session_data(session_data=self._session_data)

        message = "Behavior training runtime: Terminated."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def lick_train_state(self) -> None:
        """Configures the Mesoscope-VR system for running the lick training.

        In this state, the break is engaged to prevent the mouse from moving the wheel. The encoder module is
        disabled, and the torque sensor is enabled. The VR screens are switched off, cutting off light emission.
        The lick sensor monitoring is on to record animal licking data.
        """

        message = "Lick training mesoscope-vr state: Applied."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Ensures VR screens are turned OFF
        self._microcontrollers.disable_vr_screens()

        # Engages the break to prevent the mouse from moving the wheel
        self._microcontrollers.enable_break()

        # Ensures that encoder monitoring is disabled
        self._microcontrollers.disable_encoder_monitoring()

        # Initiates torque monitoring
        self._microcontrollers.enable_torque_monitoring()

        # Initiates lick monitoring
        self._microcontrollers.enable_lick_monitoring()

        # Generates a snapshot of the Mesoscope-VR hardware state. In turn, this data is used to parse the .npz log
        # files during processing. Note, lick training does not use the encoder and run training does not use the torque
        # sensor.
        hardware_state = MesoscopeHardwareState(
            torque_per_adc_unit=float(self._microcontrollers.torque.torque_per_adc_unit),
            lick_threshold=int(self._microcontrollers.lick.lick_threshold),
            valve_scale_coefficient=float(self._microcontrollers.valve.scale_coefficient),
            valve_nonlinearity_exponent=float(self._microcontrollers.valve.nonlinearity_exponent),
        )
        hardware_state.to_yaml(Path(self._session_data.raw_data.hardware_state_path))
        message = "Hardware state snapshot: Generated."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def run_train_state(self) -> None:
        """Configures the Mesoscope-VR system for running the run training.

        In this state, the break is disengaged, allowing the mouse to run on the wheel. The encoder module is
        enabled, and the torque sensor is disabled. The VR screens are switched off, cutting off light emission.
        The lick sensor monitoring is on to record animal licking data.
        """

        message = "Run training mesoscope-vr state: Applied."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Ensures VR screens are turned OFF
        self._microcontrollers.disable_vr_screens()

        # Disengages the break, enabling the mouse to run on the wheel
        self._microcontrollers.disable_break()

        # Ensures that encoder monitoring is enabled
        self._microcontrollers.enable_encoder_monitoring()

        # Ensures torque monitoring is disabled
        self._microcontrollers.disable_torque_monitoring()

        # Initiates lick monitoring
        self._microcontrollers.enable_lick_monitoring()

        # Generates a snapshot of the Mesoscope-VR hardware state. In turn, this data is used to parse the .npz log
        # files during processing. Note, lick training does not use the encoder and run training does not use the torque
        # sensor.
        hardware_state = MesoscopeHardwareState(
            cm_per_pulse=float(self._microcontrollers.wheel_encoder.cm_per_pulse),
            lick_threshold=int(self._microcontrollers.lick.lick_threshold),
            valve_scale_coefficient=float(self._microcontrollers.valve.scale_coefficient),
            valve_nonlinearity_exponent=float(self._microcontrollers.valve.nonlinearity_exponent),
        )
        hardware_state.to_yaml(Path(self._session_data.raw_data.hardware_state_path))
        message = "Hardware state snapshot: Generated."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def deliver_reward(self, reward_size: float = 5.0) -> None:
        """Uses the solenoid valve to deliver the requested volume of water in microliters.

        This method is used by the training runtimes to reward the animal with water as part of the training process.
        """
        self._microcontrollers.deliver_reward(volume=reward_size)

    def simulate_reward(self) -> None:
        """Uses the buzzer controlled by the valve module to deliver an audible tone without delivering any water.

        This method is used by the training runtimes when the animal refuses to consume water rewards. The tone notifies
        the animal that it performs the training as expected, while simultaneously minimizing water reward wasting.
        """
        self._microcontrollers.simulate_reward()

    @property
    def trackers(self) -> tuple[SharedMemoryArray, SharedMemoryArray, SharedMemoryArray]:
        """Returns the tracker SharedMemoryArrays for (in this order) the LickInterface, ValveInterface, and
        EncoderInterface.

        These arrays should be passed to the BehaviorVisualizer class to monitor the lick, valve and running speed data
        in real time during training.
        """
        return (
            self._microcontrollers.lick_tracker,
            self._microcontrollers.valve_tracker,
            self._microcontrollers.distance_tracker,
        )


def lick_training_logic(
    experimenter: str,
    project_name: str,
    animal_id: str,
    animal_weight: float,
    minimum_reward_delay: int = 6,
    maximum_reward_delay: int = 18,
    maximum_water_volume: float = 1.0,
    maximum_training_time: int = 20,
    maximum_unconsumed_rewards: int = 1,
    load_previous_parameters: bool = False,
) -> None:
    """Encapsulates the logic used to train animals to operate the lick port.

    The lick training consists of delivering randomly spaced 5 uL water rewards via the solenoid valve to teach the
    animal that water comes out of the lick port. Each reward is delivered after a pseudorandom delay. Reward delay
    sequence is generated before training runtime by sampling a uniform distribution that ranges from
    'minimum_reward_delay' to 'maximum_reward_delay'. The training continues either until the valve
    delivers the 'maximum_water_volume' in milliliters or until the 'maximum_training_time' in minutes is reached,
    whichever comes first.

    Args:
        experimenter: The ID (net-ID) of the experimenter conducting the training.
        project_name: The name of the project to which the trained animal belongs.
        animal_id: The numeric ID of the animal being trained.
        animal_weight: The weight of the animal, in grams, at the beginning of the training session.
        minimum_reward_delay: The minimum time, in seconds, that has to pass between delivering two consecutive rewards.
        maximum_reward_delay: The maximum time, in seconds, that can pass between delivering two consecutive rewards.
        maximum_water_volume: The maximum volume of water, in milliliters, that can be delivered during this runtime.
        maximum_training_time: The maximum time, in minutes, to run the training.
        maximum_unconsumed_rewards: The maximum number of rewards that can be delivered without the animal consuming
            them, before reward delivery (but not the training!) pauses until the animal consumes available rewards.
            If this is set to a value below 1, the unconsumed reward limit will not be enforced. A value of 1 means
            the animal has to consume each reward before getting the next reward.
        load_previous_parameters: Determines whether to override all input runtime-defining parameters with the
            parameters used during the previous session. If this is set to True, the function will ignore most input
            parameters and will instead load them from the cached session descriptor of the previous session. If the
            descriptor is not available, the function will fall back to using input parameters.
    """
    message = f"Initializing lick training runtime..."
    console.echo(message=message, level=LogLevel.INFO)

    # Queries the data acquisition system runtime parameters
    system_configuration = get_system_configuration()

    # Verifies that the target project exists
    project_folder = system_configuration.paths.root_directory.joinpath(project_name)
    if not project_folder.exists():
        message = (
            f"Unable to execute the lick training for the animal {animal_id} of project {project_name}. The target "
            f"project does not exist on the local machine. Use the 'sl-create-project' command to create the project "
            f"before running training or experiment sessions."
        )
        console.error(message=message, error=FileNotFoundError)

    # Initializes data-management classes for the runtime. Note, SessionData creates the necessary session directory
    # hierarchy as part of this initialization process
    session_data = SessionData.create(project_name=project_name, animal_id=animal_id, session_type="lick training")
    mesoscope_data = MesoscopeData(session_data=session_data)

    # Caches current sl-experiment and Python versions to disk as a version_data.yaml file.
    write_version_data(session_data)

    # Verifies that the Water Restriction log and the Surgery log Google Sheets are accessible. To do so, instantiates
    # both classes to run through the init checks. The classes are later re-instantiated during session data
    # preprocessing
    project_configuration: ProjectConfiguration = ProjectConfiguration.from_yaml(  # type: ignore
        file_path=session_data.raw_data.project_configuration_path
    )
    _ = WaterSheet(
        animal_id=int(animal_id),
        session_date=session_data.session_name,
        credentials_path=system_configuration.paths.google_credentials_path,
        sheet_id=project_configuration.water_log_sheet_id,
    )
    _ = SurgerySheet(
        project_name=project_name,
        animal_id=int(animal_id),
        credentials_path=system_configuration.paths.google_credentials_path,
        sheet_id=project_configuration.surgery_sheet_id,
    )

    # If the managed animal has cached data from a previous lick training session and the function is
    # configured to load previous data, replaces all runtime-defining parameters passed to the function with data
    # loaded from the previous session's descriptor file
    previous_descriptor_path = mesoscope_data.vrpc_persistent_data.session_descriptor_path
    if previous_descriptor_path.exists() and load_previous_parameters:
        previous_descriptor: LickTrainingDescriptor = LickTrainingDescriptor.from_yaml(  # type: ignore
            file_path=previous_descriptor_path
        )
        maximum_reward_delay = previous_descriptor.maximum_reward_delay_s
        minimum_reward_delay = previous_descriptor.minimum_reward_delay

    # Pre-generates the SessionDescriptor class and populates it with training data.
    descriptor = LickTrainingDescriptor(
        maximum_reward_delay_s=maximum_reward_delay,
        minimum_reward_delay=minimum_reward_delay,
        maximum_training_time_m=maximum_training_time,
        maximum_water_volume_ml=maximum_water_volume,
        experimenter=experimenter,
        mouse_weight_g=animal_weight,
        dispensed_water_volume_ml=0.00,
        maximum_unconsumed_rewards=maximum_unconsumed_rewards,
        incomplete=True,  # Has to be initialized to True, so that if session aborts, it is marked as incomplete
    )

    # Initializes the main runtime interface class.
    runtime = _BehaviorTraining(
        session_data=session_data,
        session_descriptor=descriptor,
    )

    # Initializes the timer used to enforce reward delays
    delay_timer = PrecisionTimer("us")

    # Uses runtime tracker extracted from the runtime instance to initialize the visualizer instance
    lick_tracker, valve_tracker, speed_tracker = runtime.trackers

    message = f"Generating the pseudorandom reward delay sequence..."
    console.echo(message=message, level=LogLevel.INFO)

    # Converts maximum volume to uL and divides it by 5 uL (reward size) to get the number of delays to sample from
    # the delay distribution
    num_samples = np.floor((maximum_water_volume * 1000) / 5).astype(np.uint64)

    # Generates samples from a uniform distribution within delay bounds
    samples = np.random.uniform(minimum_reward_delay, maximum_reward_delay, num_samples)

    # Calculates cumulative training time for each sampled delay. This communicates the total time passed when each
    # reward is delivered to the animal
    cumulative_time = np.cumsum(samples)

    # Finds the maximum number of samples that fits within the maximum training time. This assumes that to consume 1
    # ml of water, the animal would likely need more time than the maximum allowed training time, so we need to slice
    # the sampled delay array to fit within the time boundary.
    max_samples_idx = np.searchsorted(cumulative_time, maximum_training_time * 60, side="right")

    # Slices the samples array to make the total training time be roughly the maximum requested duration. Converts each
    # delay from seconds to microseconds and rounds to the nearest integer. This is done to make delays compatible with
    # PrecisionTimer class.
    reward_delays: NDArray[np.uint64] = np.round(samples[:max_samples_idx] * 1000000, decimals=0).astype(np.uint64)

    message = (
        f"Generated a sequence of {len(reward_delays)} rewards with the total cumulative runtime of "
        f"{np.round(cumulative_time[max_samples_idx - 1] / 60, decimals=3)} minutes."
    )
    console.echo(message=message, level=LogLevel.SUCCESS)

    # Since we preset the descriptor class before determining the time necessary to deliver the maximum allowed water
    # volume, the maximum training time may actually not be accurate. This would be the case if the training runtime is
    # limited by the maximum allowed water delivery volume and not time. In this case, updates the training time to
    # reflect the factual training time. This would be the case if the reward_delays array size is the same as the
    # cumulative time array size, indicating no slicing was performed due to session time constraints.
    if len(reward_delays) == len(cumulative_time):
        # Actual session time is the accumulated delay converted from seconds to minutes at the last index.
        runtime.descriptor.maximum_training_time_m = int(np.ceil(cumulative_time[-1] / 60))

    # Initializes the runtime class. This starts all necessary processes and guides the user through the steps of
    # putting the animal on the VR rig.
    runtime.start()

    # Visualizer initialization HAS to happen after the runtime start to avoid interfering with cameras.
    visualizer = BehaviorVisualizer(
        lick_tracker=lick_tracker, valve_tracker=valve_tracker, distance_tracker=speed_tracker
    )

    # Configures all system components to support lick training
    runtime.lick_train_state()

    # Initializes the listener instance used to detect training abort signals and manual reward trigger signals sent
    # via the keyboard.
    listener = KeyboardListener()

    message = (
        f"Initiating lick training procedure. Press 'ESC' + 'q' to immediately abort the training at any "
        f"time. Press 'ESC' + 'r' to deliver 5 uL of water to the animal. Press 'ESC' + 'p' to pause or resume the "
        f"paused runtime."
    )
    console.echo(message=message, level=LogLevel.INFO)

    # This tracker is used to terminate the training if manual abort command is sent via the keyboard
    terminate = False

    # Initializes assets used to ensure that the animal consumes delivered water rewards.
    if maximum_unconsumed_rewards < 1:
        # If the maximum unconsumed reward count is below 1, disables the feature by setting the number to match the
        # number of rewards to be delivered.
        maximum_unconsumed_rewards = len(reward_delays)
    unconsumed_count = 0
    previous_licks = 0

    # Loops over all delays and delivers reward via the lick tube as soon as the delay expires.
    try:
        delay_timer.reset()
        for delay in tqdm(
            reward_delays,
            desc="Delivered water rewards",
            unit="reward",
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} rewards [{elapsed}]",
        ):
            # This loop is executed while the code is waiting for the delay to pass. Anything that needs to be done
            # during the delay has to go here
            while delay_timer.elapsed < delay:
                # Updates the visualizer plot ~every 30 ms. This should be enough to reliably capture all events of
                # interest and appear visually smooth to human observers.
                visualizer.update()

                # If the animal licks during the delay period, this is interpreted as the animal consuming the previous
                # and any other leftover rewards.
                if previous_licks < visualizer.lick_count:
                    previous_licks = visualizer.lick_count
                    unconsumed_count = 0

                # If the listener detects the default abort sequence, terminates the runtime.
                if listener.exit_signal:
                    terminate = True  # Sets the terminate flag
                    break  # Breaks the while loop

                # If the listener detects a reward delivery signal, delivers the reward to the animal
                if listener.reward_signal:
                    runtime.deliver_reward(reward_size=5.0)  # Delivers 5 uL of water

                # If the listener detects a pause command, enters a holding loop.
                if listener.pause_runtime:
                    message = (
                        "Lick training runtime: paused due to user request. To resume the paused runtime, use the "
                        "'ESC + p' combination again. To abort the training, use the 'ESC + q' combination."
                    )
                    console.echo(message=message, level=LogLevel.WARNING)

                    # Blocks in-place until the user either unpauses or aborts the training.
                    while listener.pause_runtime:
                        visualizer.update()  # Continuously updates the visualizer

                        # If the user requests for the paused runtime to be aborted, terminates the runtime.
                        if listener.exit_signal:
                            terminate = True  # Sets the terminate flag
                            message = "Lick training runtime: aborted due to user request."
                            console.echo(message=message, level=LogLevel.ERROR)
                            break  # Escapes the pause 'while' loop

                    # Escapes the outer (reward delay) 'while' loop
                    if terminate:
                        break

            # If the user sent the abort command, terminates the training early
            if terminate:
                message = (
                    "Lick training abort signal detected. Aborting the lick training with a graceful shutdown "
                    "procedure."
                )
                console.echo(message=message, level=LogLevel.ERROR)
                break  # Breaks the for loop

            # Once the delay is up, triggers the solenoid valve to deliver water to the animal and starts timing the
            # next reward delay, unless unconsumed reward guard kicks in.
            if unconsumed_count < maximum_unconsumed_rewards:
                # If the animal did not accumulate the critical number of unconsumed rewards, delivers the reward.
                runtime.deliver_reward(reward_size=5.0)  # Delivers 5 uL of water

                # Increments the unconsumed reward count each time a reward is delivered
                unconsumed_count += 1

            # If the animal does not consume rewards, still issues auditory tones, but does not deliver water
            # rewards.
            else:
                runtime.simulate_reward()

            delay_timer.reset()

        # Ensures the animal has time to consume the last reward before the LickPort is moved out of its range.
        delay_timer.delay_noblock(minimum_reward_delay * 1000000)  # Converts to microseconds before delaying

    except Exception as e:
        message = (
            f"Training runtime has encountered an error and had to be terminated early. Attempting to gracefully "
            f"shutdown all assets and preserve as much of the data as possible. The encountered error message: "
            f"{str(e)}"
        )
        console.echo(message=message, level=LogLevel.ERROR)

    # Shutdown sequence:
    message = f"Training runtime: Complete."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # Terminates the listener
    listener.shutdown()

    # Closes the visualizer, as the runtime is now over
    visualizer.close()

    # Terminates the runtime. This also triggers data preprocessing and, after that, moves the data to storage
    # destinations.
    runtime.stop()


def run_training_logic(
    experimenter: str,
    project_name: str,
    animal_id: str,
    animal_weight: float,
    initial_speed_threshold: float = 0.40,
    initial_duration_threshold: float = 0.40,
    speed_increase_step: float = 0.05,
    duration_increase_step: float = 0.01,
    increase_threshold: float = 0.1,
    maximum_water_volume: float = 1.0,
    maximum_training_time: int = 20,
    maximum_idle_time: float = 0.5,
    maximum_unconsumed_rewards: int = 1,
    load_previous_parameters: bool = False,
) -> None:
    """Encapsulates the logic used to train animals to run on the wheel treadmill while being head-fixed.

    The run training consists of making the animal run on the wheel with a desired speed, in centimeters per second,
    maintained for the desired duration of time, in seconds. Each time the animal satisfies the speed and duration
    thresholds, it receives 5 uL of water reward, and the speed and durations trackers reset for the next training
    'epoch'. Each time the animal receives 'increase_threshold' of water, the speed and duration thresholds increase to
    make the task progressively more challenging. The training continues either until the training time exceeds the
    'maximum_training_time', or the animal receives the 'maximum_water_volume' of water, whichever happens earlier.

    Notes:
        During runtime, it is possible to manually increase or decrease both thresholds via 'ESC' and arrow keys. The
        speed and duration thresholds are limited to a minimum of 0.1 cm/s and 0.05 s and a maximum of 20 cm/s and
        20 s.

    Args:
        experimenter: The id of the experimenter conducting the training.
        project_name: The name of the project to which the trained animal belongs.
        animal_id: The numeric ID of the animal being trained.
        animal_weight: The weight of the animal, in grams, at the beginning of the training session.
        initial_speed_threshold: The initial running speed threshold, in centimeters per second, that the animal must
            maintain to receive water rewards.
        initial_duration_threshold: The initial duration threshold, in seconds, that the animal must maintain
            above-threshold running speed to receive water rewards.
        speed_increase_step: The step size, in centimeters per second, by which to increase the speed threshold each
            time the animal receives 'increase_threshold' milliliters of water.
        duration_increase_step: The step size, in seconds, by which to increase the duration threshold each time the
            animal receives 'increase_threshold' milliliters of water.
        increase_threshold: The volume of water received by the animal, in milliliters, after which the speed and
            duration thresholds are increased by one step. Note, the animal will at most get 'maximum_water_volume' of
            water, so this parameter effectively controls how many increases will be made during runtime, assuming the
            maximum training time is not reached.
        maximum_water_volume: The maximum volume of water, in milliliters, that can be delivered during this runtime.
        maximum_training_time: The maximum time, in minutes, to run the training.
        maximum_idle_time: The maximum time, in seconds, the animal's speed can be below the speed threshold to
            still receive water rewards. This parameter is designed to help animals with a distinct 'step' pattern to
            not lose water rewards due to taking many large steps, rather than continuously running at a stable speed.
            This parameter allows the speed to dip below the threshold for at most this number of seconds, for the
            'running epoch' to not be interrupted.
        maximum_unconsumed_rewards: The maximum number of rewards that can be delivered without the animal consuming
            them, before reward delivery (but not the training!) pauses until the animal consumes available rewards.
            If this is set to a value below 1, the unconsumed reward limit will not be enforced. A value of 1 means
            the animal has to consume all rewards before getting the next reward.
        load_previous_parameters: Determines whether to override all input runtime-defining parameters with the
            parameters used during the previous session. If this is set to True, the function will ignore most input
            parameters and will instead load them from the cached session descriptor of the previous session. If the
            descriptor is not available, the function will fall back to using input parameters.
    """
    message = f"Initializing run training runtime..."
    console.echo(message=message, level=LogLevel.INFO)

    # Queries the data acquisition system runtime parameters
    system_configuration = get_system_configuration()

    # Verifies that the target project exists
    project_folder = system_configuration.paths.root_directory.joinpath(project_name)
    if not project_folder.exists():
        message = (
            f"Unable to execute the run training for the animal {animal_id} of project {project_name}. The target "
            f"project does not exist on the local machine. Use the 'sl-create-project' command to create the project "
            f"before running training or experiment sessions."
        )
        console.error(message=message, error=FileNotFoundError)

    # Initializes data-management classes for the runtime. Note, SessionData creates the necessary session directory
    # hierarchy as part of this initialization process
    session_data = SessionData.create(project_name=project_name, animal_id=animal_id, session_type="run training")
    mesoscope_data = MesoscopeData(session_data=session_data)

    # Caches current sl-experiment and Python versions to disk as a version_data.yaml file.
    write_version_data(session_data)

    # Verifies that the Water Restriction log and the Surgery log Google Sheets are accessible. To do so, instantiates
    # both classes to run through the init checks. The classes are later re-instantiated during session data
    # preprocessing
    project_configuration: ProjectConfiguration = ProjectConfiguration.from_yaml(  # type: ignore
        file_path=session_data.raw_data.project_configuration_path
    )
    _ = WaterSheet(
        animal_id=int(animal_id),
        session_date=session_data.session_name,
        credentials_path=system_configuration.paths.google_credentials_path,
        sheet_id=project_configuration.water_log_sheet_id,
    )
    _ = SurgerySheet(
        project_name=project_name,
        animal_id=int(animal_id),
        credentials_path=system_configuration.paths.google_credentials_path,
        sheet_id=project_configuration.surgery_sheet_id,
    )

    # If the managed animal has cached data from a previous run training session and the function is
    # configured to load previous data, replaces all runtime-defining parameters passed to the function with data
    # loaded from the previous session's descriptor file
    previous_descriptor_path = mesoscope_data.vrpc_persistent_data.session_descriptor_path
    if previous_descriptor_path.exists() and load_previous_parameters:
        previous_descriptor: RunTrainingDescriptor = RunTrainingDescriptor.from_yaml(  # type: ignore
            file_path=previous_descriptor_path
        )

        # Sets initial speed and duration thresholds to the FINAL thresholds from the previous session. This way, each
        # consecutive run training session begins where the previous one has ended.
        initial_speed_threshold = previous_descriptor.final_run_speed_threshold_cm_s
        initial_duration_threshold = previous_descriptor.final_run_duration_threshold_s

    # Pre-generates the SessionDescriptor class and populates it with training data
    descriptor = RunTrainingDescriptor(
        dispensed_water_volume_ml=0.0,
        final_run_speed_threshold_cm_s=initial_speed_threshold,
        final_run_duration_threshold_s=initial_duration_threshold,
        initial_run_speed_threshold_cm_s=initial_speed_threshold,
        initial_run_duration_threshold_s=initial_duration_threshold,
        increase_threshold_ml=increase_threshold,
        run_speed_increase_step_cm_s=speed_increase_step,
        run_duration_increase_step_s=duration_increase_step,
        maximum_training_time_m=maximum_training_time,
        maximum_water_volume_ml=maximum_water_volume,
        maximum_unconsumed_rewards=maximum_unconsumed_rewards,
        maximum_idle_time_s=maximum_idle_time,
        experimenter=experimenter,
        mouse_weight_g=animal_weight,
        incomplete=True,  # Has to be initialized to True, so that if session aborts, it is marked as incomplete
    )

    # Initializes the main runtime interface class. Note, most class parameters are statically configured to work for
    # the current VRPC setup and may need to be adjusted as that setup evolves over time.
    runtime = _BehaviorTraining(
        session_data=session_data,
        session_descriptor=descriptor,
    )

    # Initializes the timers used during runtime
    runtime_timer = PrecisionTimer("s")
    speed_timer = PrecisionTimer("ms")

    # Initializes assets used to guard against interrupting run epochs for mice that take many large steps. For mice
    # with a distinct walking pattern of many very large steps, the speed transiently dips below the threshold for a
    # very brief moment of time, flagging the epoch as unrewarded. To avoid this issue, instead of interrupting the
    # epoch outright, we now allow the speed to be below the threshold for a short period of time. These assets
    # help with that task pattern.
    epoch_timer = PrecisionTimer("ms")
    epoch_timer_engaged: bool = False
    maximum_idle_time = max(0.0, maximum_idle_time)  # Ensures positive values or zero
    maximum_idle_time *= 1000  # Converts to milliseconds

    # Initializes assets used to ensure that the animal consumes delivered water rewards.
    if maximum_unconsumed_rewards < 1:
        # If the maximum unconsumed reward count is below 1, disables the feature by setting the number to match the
        # maximum number of rewards that can possibly be delivered during runtime.
        maximum_unconsumed_rewards = int(np.ceil(maximum_water_volume / 0.005))
    previous_licks = 0
    unconsumed_count = 0

    # Converts all arguments used to determine the speed and duration threshold over time into numpy variables to
    # optimize main loop runtime speed:
    initial_speed = np.float64(initial_speed_threshold)  # In centimeters per second
    maximum_speed = np.float64(20)  # In centimeters per second
    speed_step = np.float64(speed_increase_step)  # In centimeters per second

    initial_duration = np.float64(initial_duration_threshold * 1000)  # In milliseconds
    maximum_duration = np.float64(20000)  # In milliseconds
    duration_step = np.float64(duration_increase_step * 1000)  # In milliseconds

    # The way 'increase_threshold' is used requires it to be greater than 0. So if a threshold of 0 is passed, the
    # system sets it to a very small number instead. which functions similar to it being 0, but does not produce an
    # error.
    if increase_threshold < 0:
        increase_threshold = 0.000000000001

    water_threshold = np.float64(increase_threshold * 1000)  # In microliters
    maximum_volume = np.float64(maximum_water_volume * 1000)  # In microliters

    # Converts the training time from minutes to seconds to make it compatible with the timer precision.
    training_time = maximum_training_time * 60

    # Uses runtime trackers extracted from the runtime instance to initialize the visualizer instance
    lick_tracker, valve_tracker, speed_tracker = runtime.trackers

    # Initializes the runtime class. This starts all necessary processes and guides the user through the steps of
    # putting the animal on the VR rig.
    runtime.start()

    # Visualizer initialization HAS to happen after the runtime start to avoid interfering with cameras.
    visualizer = BehaviorVisualizer(
        lick_tracker=lick_tracker, valve_tracker=valve_tracker, distance_tracker=speed_tracker
    )

    # Updates the threshold lines to use the initial speed and duration values
    visualizer.update_speed_thresholds(speed_threshold=initial_speed, duration_threshold=initial_duration)

    # Configures all system components to support run training
    runtime.run_train_state()

    # Initializes the listener instance used to enable keyboard-driven training runtime control.
    listener = KeyboardListener()

    message = (
        f"Initiating run training procedure. Press 'ESC' + 'q' to immediately abort the training at any "
        f"time. Press 'ESC' + 'r' to deliver 5 uL of water to the animal. Use 'ESC' + Up / Down arrows to modify the "
        f"running speed threshold. Use 'ESC' + Left / Right arrows to modify the running duration threshold. Press "
        f"'ESC' + 'p' to pause or resume the paused runtime."
    )
    console.echo(message=message, level=LogLevel.INFO)

    # Creates a tqdm progress bar that tracks the overall training progress by communicating the total volume of water
    # delivered to the animal
    progress_bar = tqdm(
        total=round(maximum_water_volume, ndigits=3),
        desc="Delivered water volume",
        unit="ml",
        bar_format="{l_bar}{bar}| {n:.3f}/{total:.3f} {postfix}",
    )

    # Tracks the data necessary to update the training progress bar
    previous_time = 0

    # Tracks when speed and / or duration thresholds are updated. This is necessary to redraw the threshold lines in
    # the visualizer plot
    previous_speed_threshold = copy.copy(initial_speed)
    previous_duration_threshold = copy.copy(initial_duration)

    # Also pre-initializes the speed and duration trackers
    speed_threshold: np.float64 = np.float64(0)
    duration_threshold: np.float64 = np.float64(0)

    # If the runtime is paused, this is used to extend the training runtime to account for the time spent in the
    # paused state.
    additional_time = 0

    # Initializes the main training loop. The loop will run either until the total training time expires, the maximum
    # volume of water is delivered or the loop is aborted by the user.
    try:
        runtime_timer.reset()
        speed_timer.reset()  # It is critical to reset BOTh timers at the same time.
        while runtime_timer.elapsed < (training_time + additional_time):
            # Updates the total volume of water dispensed during runtime at each loop iteration.
            dispensed_water_volume = valve_tracker.read_data(index=1, convert_output=False)

            # Determines how many times the speed and duration thresholds have been increased based on the difference
            # between the total delivered water volume and the increase threshold. This dynamically adjusts the running
            # speed and duration thresholds with delivered water volume, ensuring the animal has to try progressively
            # harder to keep receiving water.
            increase_steps: np.float64 = np.floor(dispensed_water_volume / water_threshold)

            # Determines the speed and duration thresholds for each cycle. This factors in the user input via keyboard.
            # Note, user input has a static resolution of 0.1 cm/s per step and 50 ms per step.
            speed_threshold = np.clip(
                a=initial_speed + (increase_steps * speed_step) + (listener.speed_modifier * 0.01),
                a_min=0.1,  # Minimum value
                a_max=maximum_speed,  # Maximum value
            )
            duration_threshold = np.clip(
                a=initial_duration + (increase_steps * duration_step) + (listener.duration_modifier * 10),
                a_min=50,  # Minimum value (0.05 seconds == 50 milliseconds)
                a_max=maximum_duration,  # Maximum value
            )

            # If any of the threshold changed relative to the previous loop iteration, updates the visualizer and
            # previous threshold trackers with new data.
            if duration_threshold != previous_duration_threshold or previous_speed_threshold != speed_threshold:
                visualizer.update_speed_thresholds(speed_threshold, duration_threshold)
                previous_speed_threshold = speed_threshold
                previous_duration_threshold = duration_threshold

            # Reads the animal's running speed from the visualizer. The visualizer uses the distance tracker to
            # calculate the running speed of the animal over 100 millisecond windows. This accesses the result of this
            # computation and uses it to determine whether the animal is performing above the threshold.
            current_speed = visualizer.running_speed

            # If the animal licks during the period that separates two rewards, this is interpreted as the animal
            # consuming the previous and any other leftover rewards.
            if previous_licks < visualizer.lick_count:
                previous_licks = visualizer.lick_count
                unconsumed_count = 0

            # If the speed is above the speed threshold, and the animal has been maintaining the above-threshold speed
            # for the required duration, delivers 5 uL of water. If the speed is above threshold, but the animal has
            # not yet maintained the required duration, the loop will keep cycling and accumulating the timer count.
            # This is done until the animal either reaches the required duration or drops below the speed threshold.
            if current_speed >= speed_threshold and speed_timer.elapsed >= duration_threshold:
                # Only issues the rewards if the unconsumed reward counter is below the threshold.
                if unconsumed_count < maximum_unconsumed_rewards:
                    runtime.deliver_reward(reward_size=5.0)  # Delivers 5 uL of water

                    # 5 uL == 0.005 ml
                    # Updates the progress bar whenever the animal receives (automated) rewards. The progress bar
                    # purposefully does not track 'manual' water rewards.
                    progress_bar.update(0.005)

                    # Increments the unconsumed reward count each time a reward is delivered
                    unconsumed_count += 1

                # If the animal does not consume rewards, still issues auditory tones, but does not deliver water
                # rewards.
                else:
                    runtime.simulate_reward()

                # Also resets the timer. While mice typically stop to consume water rewards, which would reset the
                # timer, this guards against animals that carry on running without consuming water rewards.
                speed_timer.reset()

                # If the epoch timer was active for the current epoch, resets the timer
                epoch_timer_engaged = False

            # If the current speed is below the speed threshold, acts depending on whether the runtime is configured to
            # allow dipping below the threshold
            elif current_speed < speed_threshold:
                # If the user did not allow dipping below the speed threshold, resets the run duration timer.
                if maximum_idle_time == 0:
                    speed_timer.reset()

                # If the user has enabled brief dips below the speed threshold, starts the epoch timer to ensure the
                # animal recovers the speed in the allotted time.
                elif not epoch_timer_engaged:
                    epoch_timer.reset()
                    epoch_timer_engaged = True

                # If epoch timer is enabled, checks whether the animal has failed to recover its running speed in time.
                # If so, resets the run duration timer.
                elif epoch_timer.elapsed >= maximum_idle_time:
                    speed_timer.reset()
                    epoch_timer_engaged = False

            # If the animal is maintaining the required speed and the epoch timer was activated by the animal dipping
            # below the speed threshold, deactivates the timer. This is essential for ensuring the 'step discount'
            # time is applied to each case of speed dipping below the speed threshold, rather than the entire run epoch.
            elif epoch_timer_engaged and current_speed >= speed_threshold and speed_timer.elapsed < duration_threshold:
                epoch_timer_engaged = False

            # Updates the time display when each second passes. This updates the 'suffix' of the progress bar to keep
            # track of elapsed training time. Accounts for any additional time spent in the 'paused' state.
            elapsed_time = runtime_timer.elapsed - additional_time
            if elapsed_time > previous_time:
                previous_time = elapsed_time  # Updates previous time

                # Updates the time display without advancing the progress bar
                elapsed_minutes = int(elapsed_time // 60)
                elapsed_seconds = int(elapsed_time % 60)
                progress_bar.set_postfix_str(
                    f"Time: {elapsed_minutes:02d}:{elapsed_seconds:02d}/{maximum_training_time:02d}:00"
                )

                # Refreshes the display to show updated time without changing progress
                progress_bar.refresh()

            # Updates the visualizer plot
            visualizer.update()

            # If the total volume of water dispensed during runtime exceeds the maximum allowed volume, aborts the
            # training early with a success message.
            if dispensed_water_volume >= maximum_volume:
                message = (
                    f"Run training has delivered the maximum allowed volume of water ({maximum_volume} uL). Aborting "
                    f"the training process."
                )
                console.echo(message=message, level=LogLevel.SUCCESS)
                break

            # If the listener detects a reward delivery signal, delivers the reward to the animal.
            if listener.reward_signal:
                runtime.deliver_reward(reward_size=5.0)  # Delivers 5 uL of water

            # If the user sent the abort command, terminates the training early with an error message.
            if listener.exit_signal:
                message = (
                    "Run training abort signal detected. Aborting the training with a graceful shutdown procedure."
                )
                console.echo(message=message, level=LogLevel.ERROR)
                break

            # If the listener detects a pause command, enters a holding loop.
            if listener.pause_runtime:
                pause_start = runtime_timer.elapsed
                message = (
                    "Run training runtime: paused due to user request. To resume the paused runtime, use the "
                    "'ESC + p' combination again. To abort the training, use the 'ESC + q' combination."
                )
                console.echo(message=message, level=LogLevel.WARNING)

                # Blocks in-place until the user either unpauses or aborts the training.
                abort_stage: bool = False
                while listener.pause_runtime:
                    visualizer.update()  # Continuously updates the visualizer

                    # If the user requests for the paused runtime to be aborted, terminates the runtime.
                    if listener.exit_signal:
                        abort_stage = True
                        message = f"Run training runtime: aborted due to user request."
                        console.echo(message=message, level=LogLevel.ERROR)
                        break  # Escapes the pause 'while' loop

                # Updates the 'additional time' value to reflect the time spent inside the 'paused' state. This
                # increases the training time to counteract the duration of the 'paused' state.
                additional_time += runtime_timer.elapsed - pause_start

                # Escapes the outer (experiment state) 'while loop'
                if abort_stage:
                    break

        # Close the progress bar
        progress_bar.close()

    except Exception as e:
        message = (
            f"Training runtime has encountered an error and had to be terminated early. Attempting to gracefully "
            f"shutdown all assets and preserve as much of the data as possible. The encountered error message: "
            f"{str(e)}"
        )
        console.echo(message=message, level=LogLevel.ERROR)

    # Shutdown sequence:
    message = f"Training runtime: Complete."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # Directly overwrites the final running speed and duration thresholds in the descriptor instance stored in the
    # runtime attributes. This ensures the descriptor properly reflects the final thresholds used at the end of
    # the training.
    if not isinstance(runtime.descriptor, LickTrainingDescriptor):  # This is to appease mypy
        runtime.descriptor.final_run_speed_threshold_cm_s = float(speed_threshold)
        runtime.descriptor.final_run_duration_threshold_s = float(duration_threshold / 1000)  # Converts from s to ms

    # Terminates the listener
    listener.shutdown()

    # Closes the visualizer, as the runtime is now over
    visualizer.close()

    # Terminates the runtime. This also triggers data preprocessing and, after that, moves the data to storage
    # destinations.
    runtime.stop()


def experiment_logic(
    experimenter: str,
    project_name: str,
    experiment_name: str,
    animal_id: str,
    animal_weight: float,
) -> None:
    """Encapsulates the logic used to run experiments via the Mesoscope-VR system.

    This function can be used to execute any valid experiment using the Mesoscope-VR system. Each experiment should be
    broken into one or more experiment states (phases), such as 'baseline', 'task' and 'cooldown'. Furthermore, each
    experiment state can use one or more VR system states. Currently, the VR system has two states: rest (1) and run
    (2). The states are used to broadly configure the Mesoscope-VR system, and they determine which systems are active
    and what data is collected (see library ReadMe for more details on VR states).

    Primarily, this function is concerned with iterating over the states stored inside the experiment_state_sequence
    tuple. Each experiment and VR state combination is maintained for the requested duration of seconds. Once all states
    have been executed, the experiment runtime ends. Under this design pattern, each experiment is conceptualized as
    a sequence of states.

    Notes:
        During experiment runtimes, the task logic and the Virtual Reality world are resolved via the Unity game engine.
        This function itself does not resolve the task logic, it is only concerned with iterating over experiment
        states, controlling the VR system, and monitoring user command issued via keyboard.

        Similar to all other runtime functions, this function contains all necessary bindings to set up, execute, and
        terminate an experiment runtime. Custom projects should implement a cli that calls this function with
        project-specific parameters.

    Args:
        experimenter: The id of the experimenter conducting the experiment.
        project_name: The name of the project for which the experiment is conducted.
        experiment_name: The name or ID of the experiment to be conducted.
        animal_id: The numeric ID of the animal participating in the experiment.
        animal_weight: The weight of the animal, in grams, at the beginning of the experiment session.
    """
    message = f"Initializing {experiment_name} experiment runtime..."
    console.echo(message=message, level=LogLevel.INFO)

    # Queries the data acquisition system runtime parameters
    system_configuration = get_system_configuration()

    # Verifies that the target project exists
    project_folder = system_configuration.paths.root_directory.joinpath(project_name)
    if not project_folder.exists():
        message = (
            f"Unable to execute the {experiment_name} experiment for the animal {animal_id} of project {project_name}. "
            f"The target project does not exist on the local machine. Use the 'sl-create-project' command to create "
            f"the project before running training or experiment sessions."
        )
        console.error(message=message, error=FileNotFoundError)

    # Initializes the SessionData and creates the necessary session directory hierarchy as part of this initialization
    # process
    session_data = SessionData.create(
        project_name=project_name,
        animal_id=animal_id,
        session_type="mesoscope experiment",
        experiment_name=experiment_name,
    )

    # Caches current sl-experiment and Python versions to disk as a version_data.yaml file.
    write_version_data(session_data)

    # Verifies that the Water Restriction log and the Surgery log Google Sheets are accessible. To do so, instantiates
    # both classes to run through the init checks. The classes are later re-instantiated during session data
    # preprocessing
    project_configuration: ProjectConfiguration = ProjectConfiguration.from_yaml(  # type: ignore
        file_path=session_data.raw_data.project_configuration_path
    )
    _ = WaterSheet(
        animal_id=int(animal_id),
        session_date=session_data.session_name,
        credentials_path=system_configuration.paths.google_credentials_path,
        sheet_id=project_configuration.water_log_sheet_id,
    )
    _ = SurgerySheet(
        project_name=project_name,
        animal_id=int(animal_id),
        credentials_path=system_configuration.paths.google_credentials_path,
        sheet_id=project_configuration.surgery_sheet_id,
    )

    # Uses initialized SessionData instance to load the experiment configuration data
    experiment_config: MesoscopeExperimentConfiguration = MesoscopeExperimentConfiguration.from_yaml(  # type: ignore
        file_path=Path(session_data.raw_data.experiment_configuration_path)
    )

    # Verifies that all Mesoscope-VR states used during experiments are valid
    valid_states = {1, 2}
    for state in experiment_config.experiment_states.values():
        if state.system_state_code not in valid_states:
            message = (
                f"Invalid Mesoscope-VR system state code {state.system_state_code} encountered when verifying "
                f"{experiment_name} experiment configuration. Currently, only codes 1 (rest) and 2 (run) are supported "
                f"for the Mesoscope-VR system."
            )
            console.error(message=message, error=ValueError)

    # Generates the session descriptor class
    descriptor = MesoscopeExperimentDescriptor(
        experimenter=experimenter, mouse_weight_g=animal_weight, dispensed_water_volume_ml=0.0
    )

    # Initializes the main runtime interface class.
    runtime = _MesoscopeExperiment(
        experiment_configuration=experiment_config,
        session_data=session_data,
        session_descriptor=descriptor,
    )

    runtime_timer = PrecisionTimer("s")  # Initializes the timer to enforce experiment state durations

    # Uses runtime trackers extracted from the runtime instance to initialize the visualizer instance
    lick_tracker, valve_tracker, speed_tracker = runtime.trackers

    # Initializes the runtime class. This starts all necessary processes and guides the user through the steps of
    # putting the animal on the VR rig.
    runtime.start()

    # Visualizer initialization HAS to happen after the runtime start to avoid interfering with cameras.
    visualizer = BehaviorVisualizer(
        lick_tracker=lick_tracker, valve_tracker=valve_tracker, distance_tracker=speed_tracker
    )

    # Initializes the keyboard listener to support aborting test runtimes.
    listener = KeyboardListener()

    message = (
        f"Initiating Mesoscope experiment. Press 'ESC' + 'q' to immediately abort the experiment runtime at any time. "
        f"Press 'ESC' + 'r' to deliver 5 uL of water to the animal. Press 'ESC' + 'p' to pause or resume the paused "
        f"runtime."
    )
    console.echo(message=message, level=LogLevel.INFO)

    # Main runtime loop. It loops over all submitted experiment states and ends the runtime after executing the last
    # state
    try:
        for state in experiment_config.experiment_states.values():
            runtime_timer.reset()  # Resets the timer

            # Sets the Experiment state
            runtime.change_experiment_state(state.experiment_state_code)

            # Resolves and sets the Mesoscope-VR system state
            if state.system_state_code == 1:
                runtime.rest()
            elif state.system_state_code == 2:
                runtime.run()

            # Creates a tqdm progress bar for the current experiment state
            with tqdm(
                total=state.state_duration_s,
                desc=f"Executing experiment state {state.experiment_state_code}",
                bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt}s",
            ) as pbar:
                previous_seconds = 0

                # If the runtime is paused, this is used to extend the experiment state duration to account for the time
                # spent in the paused state.
                additional_time = 0

                while runtime_timer.elapsed < (state.state_duration_s + additional_time):
                    visualizer.update()  # Continuously updates the visualizer

                    # Updates the progress bar every second. While the current implementation is technically not safe,
                    # we know that the loop will cycle much faster than 1 second, so it should not be possible for the
                    # delta to ever exceed 1 second. Note, discounts any time spent inside the paused state.
                    if (runtime_timer.elapsed - additional_time) > previous_seconds:
                        pbar.update(1)
                        previous_seconds = runtime_timer.elapsed - additional_time

                    # If the user sent the abort command, terminates the runtime early with an error message.
                    if listener.exit_signal:
                        message = f"Experiment runtime: aborted due to user request."
                        console.echo(message=message, level=LogLevel.ERROR)
                        break

                    # If the listener detects a reward delivery signal, delivers the reward to the animal
                    if listener.reward_signal:
                        runtime.deliver_reward(reward_size=5.0)  # Delivers 5 uL of water

                    # If the listener detects a pause command, enters a holding loop.
                    if listener.pause_runtime:
                        pause_start = runtime_timer.elapsed
                        message = (
                            "Experiment runtime: paused due to user request. To resume the paused runtime, use the "
                            "'ESC + p' combination again. To abort the paused experiment runtime, use the 'ESC + q' "
                            "combination."
                        )
                        console.echo(message=message, level=LogLevel.WARNING)

                        # Switches the runtime control system to the 'idle' state.
                        runtime.idle()

                        # Blocks in-place until the user either unpauses or aborts the current experiment stage.
                        abort_stage: bool = False
                        while listener.pause_runtime:
                            visualizer.update()  # Continuously updates the visualizer

                            # If the user requests for the paused stage to be aborted, terminates the runtime.
                            if listener.exit_signal:
                                abort_stage = True
                                message = f"Experiment runtime: aborted due to user request."
                                console.echo(message=message, level=LogLevel.ERROR)
                                break  # Escapes the pause 'while' loop

                        # Updates the 'additional time' value to reflect the time spent inside the 'paused' state. This
                        # increases the experiment stage duration to counteract the duration of the 'paused' state.
                        additional_time += runtime_timer.elapsed - pause_start

                        # Escapes the outer (experiment state) 'while loop
                        if abort_stage:
                            break
                        else:
                            # Otherwise, if the user has unpaused the runtime, restores the system to the appropriate
                            # state.
                            if state.system_state_code == 1:
                                runtime.rest()
                            elif state.system_state_code == 2:
                                runtime.run()

    except Exception as e:
        message = (
            f"Experiment runtime has encountered an error and had to be terminated early. Attempting to gracefully "
            f"shutdown all assets and preserve as much of the data as possible. The encountered error message: "
            f"{str(e)}"
        )
        console.echo(message=message, level=LogLevel.ERROR)

    # Shutdown sequence:
    message = f"Experiment runtime: Complete."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # Closes the visualizer, as the runtime is now over
    visualizer.close()

    # Terminates the runtime. This also triggers data preprocessing and, after that, moves the data to storage
    # destinations.
    runtime.stop()


def maintenance_logic() -> None:
    """Encapsulates the logic used to maintain various components of the Mesoscope-VR system.

    This runtime is primarily used to verify and, if necessary, recalibrate the water valve between training or
    experiment days and to maintain the surface material of the running wheel.
    """

    message = f"Initializing Mesoscope-VR system maintenance runtime..."
    console.echo(message=message, level=LogLevel.INFO)

    # Queries the data acquisition system runtime parameters. This runtime only needs access to the base acquisition
    # system configuration data, as it does not generate any new data by itself.
    system_configuration = get_system_configuration()

    # Initializes a timer used to optimize console printouts for using the valve in debug mode (which also posts
    # things to console).
    delay_timer = PrecisionTimer("s")

    message = f"Initializing interface classes..."
    console.echo(message=message, level=LogLevel.INFO)

    # All calibration procedures are executed in a temporary directory deleted after runtime.
    with tempfile.TemporaryDirectory(prefix="sl_maintenance_") as output_dir:
        output_path: Path = Path(output_dir)

        # Initializes the data logger. Due to how the MicroControllerInterface class is implemented, this is required
        # even for runtimes that do not need to save data.
        logger = DataLogger(
            output_directory=output_path,
            instance_name="temp",
            exist_ok=True,
            process_count=1,
            thread_count=10,
        )
        logger.start()

        # While we can connect to ports managed by ZaberLauncher, ZaberLauncher cannot connect to ports managed via
        # software. Therefore, we have to make sure ZaberLauncher is running before connecting to motors.
        message = (
            "Preparing to connect to all Zaber motor controllers. Make sure that ZaberLauncher app is running before "
            "proceeding further. If ZaberLauncher is not running, you WILL NOT be able to manually control Zaber motor "
            "positions until you reset the runtime."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Providing the class with an invalid path makes sure it falls back to using default positions cached in
        # non-volatile memory of each device.
        zaber_motors: ZaberMotors = ZaberMotors(zaber_positions_path=output_path.joinpath("invalid_path.yaml"))

        # Initializes the interface for the Actor MicroController that manages the valve and break modules.
        valve: ValveInterface = ValveInterface(
            valve_calibration_data=system_configuration.microcontrollers.valve_calibration_data,  # type: ignore
            debug=True,  # Hardcoded to True during maintenance
        )
        wheel: BreakInterface = BreakInterface(
            minimum_break_strength=system_configuration.microcontrollers.minimum_break_strength_g_cm,
            maximum_break_strength=system_configuration.microcontrollers.maximum_break_strength_g_cm,
            object_diameter=system_configuration.microcontrollers.wheel_diameter_cm,
            debug=True,  # Hardcoded to True during maintenance
        )
        controller: MicroControllerInterface = MicroControllerInterface(
            controller_id=np.uint8(101),  # Hardcoded
            microcontroller_serial_buffer_size=8192,  # Hardcoded
            microcontroller_usb_port=system_configuration.microcontrollers.actor_port,
            data_logger=logger,
            module_interfaces=(valve, wheel),
        )
        controller.start()
        controller.unlock_controller()  # Unlocks actor controller to allow manipulating managed hardware

        # Delays for 1 second for the valve to initialize and send the state message. This avoids the visual clash
        # with the zaber positioning dialog
        delay_timer.delay_noblock(delay=1)

        message = f"Actor MicroController interface: Initialized."
        console.echo(message=message, level=LogLevel.SUCCESS)

        message = (
            "Preparing to move Zaber motors into maintenance position. Remove the mesoscope objective, swivel out the "
            "VR screens, and make sure the animal is NOT mounted on the rig. Failure to fulfill these steps may DAMAGE "
            "the mesoscope and / or HARM the animal."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        zaber_motors.prepare_motors()  # homes all motors
        zaber_motors.maintenance_position()  # Moves all motors to maintenance position

        message = f"Zaber motors: Positioned for Mesoscope-VR system maintenance."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Notifies the user about supported calibration commands
        message = (
            "Supported valve commands: open, close, close_10, reference, reward, calibrate_15, calibrate_30, "
            "calibrate_45, calibrate_60. Supported break (wheel) commands: lock, unlock. Use 'q' command to terminate "
            "the runtime."
        )
        console.echo(message=message, level=LogLevel.INFO)

        # Precomputes correct auditory tone duration from Mesoscope-VR configuration
        tone_duration: float = convert_time(  # type: ignore
            from_units="ms", to_units="us", time=system_configuration.microcontrollers.auditory_tone_duration_ms
        )

        while True:
            command = input()  # Silent input to avoid visual spam.

            if command == "open":
                message = f"Opening the valve..."
                console.echo(message=message, level=LogLevel.INFO)
                valve.toggle(state=True)

            if command == "close":
                message = f"Closing the valve..."
                console.echo(message=message, level=LogLevel.INFO)
                valve.toggle(state=False)

            if command == "close_10":
                message = f"Closing the valve after a 10-second delay..."
                console.echo(message=message, level=LogLevel.INFO)
                start = delay_timer.elapsed
                previous_time = delay_timer.elapsed
                while delay_timer.elapsed - start < 10:
                    if previous_time != delay_timer.elapsed:
                        previous_time = delay_timer.elapsed
                        console.echo(
                            message=f"Remaining time: {10 - (delay_timer.elapsed - start)} seconds...",
                            level=LogLevel.INFO,
                        )
                valve.toggle(state=False)  # Closes the valve after a 10-second delay

            if command == "reward":
                message = f"Delivering 5 uL water reward..."
                console.echo(message=message, level=LogLevel.INFO)
                pulse_duration = valve.get_duration_from_volume(target_volume=5.0)
                valve.set_parameters(
                    pulse_duration=pulse_duration,
                    calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons
                    calibration_count=np.uint16(system_configuration.microcontrollers.valve_calibration_pulse_count),
                    tone_duration=np.uint32(tone_duration),
                )
                valve.send_pulse()

            if command == "reference":
                message = f"Running the reference valve calibration procedure..."
                console.echo(message=message, level=LogLevel.INFO)
                message = f"Expecting to dispense 1 ml of water (200 pulses x 5 uL each)..."
                console.echo(message=message, level=LogLevel.INFO)
                pulse_duration = valve.get_duration_from_volume(target_volume=5.0)
                valve.set_parameters(
                    pulse_duration=pulse_duration,  # Hardcoded to 5 uL for consistent behavior
                    calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons
                    calibration_count=np.uint16(200),  # Hardcoded to 200 pulses for consistent behavior
                    tone_duration=np.uint32(tone_duration),
                )
                valve.calibrate()

            if command == "calibrate_15":
                message = f"Running 15 ms pulse duration valve calibration..."
                console.echo(message=message, level=LogLevel.INFO)
                valve.set_parameters(
                    pulse_duration=np.uint32(15000),  # 15 ms in us
                    calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons
                    calibration_count=np.uint16(system_configuration.microcontrollers.valve_calibration_pulse_count),
                    tone_duration=np.uint32(tone_duration),
                )
                valve.calibrate()

            if command == "calibrate_30":
                message = f"Running 30 ms pulse valve calibration..."
                console.echo(message=message, level=LogLevel.INFO)
                valve.set_parameters(
                    pulse_duration=np.uint32(30000),  # 30 ms in us
                    calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons
                    calibration_count=np.uint16(system_configuration.microcontrollers.valve_calibration_pulse_count),
                    tone_duration=np.uint32(tone_duration),
                )
                valve.calibrate()

            if command == "calibrate_45":
                message = f"Running 45 ms pulse valve calibration..."
                console.echo(message=message, level=LogLevel.INFO)
                valve.set_parameters(
                    pulse_duration=np.uint32(45000),  # 45 ms in us
                    calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons
                    calibration_count=np.uint16(system_configuration.microcontrollers.valve_calibration_pulse_count),
                    tone_duration=np.uint32(tone_duration),
                )
                valve.calibrate()

            if command == "calibrate_60":
                message = f"Running 60 ms pulse valve calibration..."
                console.echo(message=message, level=LogLevel.INFO)
                valve.set_parameters(
                    pulse_duration=np.uint32(60000),  # 60 ms in us
                    calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons
                    calibration_count=np.uint16(system_configuration.microcontrollers.valve_calibration_pulse_count),
                    tone_duration=np.uint32(tone_duration),
                )
                valve.calibrate()

            if command == "lock":
                message = f"Locking wheel break..."
                console.echo(message=message, level=LogLevel.INFO)
                wheel.toggle(state=True)

            if command == "unlock":
                message = f"Unlocking wheel break..."
                console.echo(message=message, level=LogLevel.INFO)
                wheel.toggle(state=False)

            if command == "q":
                message = f"Terminating Mesoscope-VR maintenance runtime..."
                console.echo(message=message, level=LogLevel.INFO)
                break

        # Instructs the user to remove all objects that may interfere with moving the motors.
        message = (
            "Preparing to reset all Zaber motors. Remove all objects used during Mesoscope-VR maintenance, such as "
            "water collection flasks, from the Mesoscope-VR cage."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Shuts down zaber bindings
        zaber_motors.park_position()
        zaber_motors.disconnect()

        # Shuts down microcontroller interfaces
        controller.stop()

        message = f"Actor MicroController interface: Terminated."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Stops the data logger
        logger.stop()

        message = f"Mesoscope-VR system maintenance runtime: Terminated."
        console.echo(message=message, level=LogLevel.SUCCESS)


def window_checking_logic(
    project_name: str,
    animal_id: str,
) -> None:
    """Encapsulates the logic used to verify the surgery quality (cranial window) and generate the initial snapshot of
    the Mesoscope-VR system configuration for a newly added animal of the target project.

    This function is used when new animals are added to the project, before any other training or experiment runtime.
    Primarily, it is used to verify that the surgery went as expected and the animal is fit for providing high-quality
    scientific data. As part of this process, the function also generates the snapshot of zaber motor positions and the
    mesoscope objective position to be reused by future sessions.

    Notes:
        This function largely behaves similar to all other training and experiment session runtimes. However, it does
        not use most of the Mesoscope-VR components and does not make most of the runtime data files typically generated
        by other sessions. All window checking sessions are automatically marked as 'incomplete' and excluded from
        automated data processing.

    Args:
        project_name: The name of the project to which the checked animal belongs.
        animal_id: The numeric ID of the animal whose cranial window is being checked.
    """
    message = f"Initializing window checking runtime..."
    console.echo(message=message, level=LogLevel.INFO)

    # Queries the data acquisition system runtime parameters.
    system_configuration = get_system_configuration()

    # Verifies that the target project exists
    project_folder = system_configuration.paths.root_directory.joinpath(project_name)
    if not project_folder.exists():
        message = (
            f"Unable to execute the run training for the animal {animal_id} of project {project_name}. The target "
            f"project does not exist on the local machine. Use the 'sl-create-project' command to create the project "
            f"before running training or experiment sessions."
        )
        console.error(message=message, error=FileNotFoundError)

    # Initializes the SessionData and MesoscopeData classes for the session.
    session_data = SessionData.create(
        project_name=project_name,
        animal_id=animal_id,
        session_type="window checking",
    )
    mesoscope_data = MesoscopeData(session_data=session_data)

    # Caches current sl-experiment and Python versions to disk as a version_data.yaml file.
    write_version_data(session_data)

    # Verifies that the Surgery log Google Sheet is accessible. To do so, instantiates its interface class to run
    # through the init checks. The class is later re-instantiated during session data preprocessing
    project_configuration: ProjectConfiguration = ProjectConfiguration.from_yaml(  # type: ignore
        file_path=session_data.raw_data.project_configuration_path
    )
    _ = SurgerySheet(
        project_name=project_name,
        animal_id=int(animal_id),
        credentials_path=system_configuration.paths.google_credentials_path,
        sheet_id=project_configuration.surgery_sheet_id,
    )

    message = f"Initializing interface classes..."
    console.echo(message=message, level=LogLevel.INFO)

    # Initializes the data logger. This initialization follows the same procedure as the BehaviorTraining or
    # MesoscopeExperiment classes
    logger: DataLogger = DataLogger(
        output_directory=Path(session_data.raw_data.raw_data_path),
        instance_name="behavior",  # Creates behavior_log subfolder under raw_data
        sleep_timer=0,
        exist_ok=True,
        process_count=1,
        thread_count=10,
    )
    logger.start()

    # Initializes the face camera. Body cameras are not used during window checking.
    cameras = VideoSystems(data_logger=logger, output_directory=session_data.raw_data.camera_data_path)
    cameras.start_face_camera()
    message = f"Face camera display: Started."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # While we can connect to ports managed by ZaberLauncher, ZaberLauncher cannot connect to ports managed via
    # software. Therefore, we have to make sure ZaberLauncher is running before connecting to motors.
    message = (
        "Preparing to connect to all Zaber motor controllers. Make sure that ZaberLauncher app is running before "
        "proceeding further. If ZaberLauncher is not running, you WILL NOT be able to manually control Zaber motor "
        "positions until you reset the runtime."
    )
    console.echo(message=message, level=LogLevel.WARNING)
    input("Enter anything to continue: ")

    # Initializes the Zaber motors interface
    zaber_motors: ZaberMotors = ZaberMotors(
        zaber_positions_path=mesoscope_data.vrpc_persistent_data.zaber_positions_path
    )

    # Initializes the Zaber positioning sequence. This relies heavily on user feedback to confirm that it is safe to
    # proceed with motor movements.
    message = (
        "Preparing to move Zaber motors into mounting position. Remove the mesoscope objective, swivel out the VR "
        "screens, and make sure the animal is NOT mounted on the rig. Failure to fulfill these steps may DAMAGE "
        "the mesoscope and / or HARM the animal."
    )
    console.echo(message=message, level=LogLevel.WARNING)
    input("Enter anything to continue: ")

    # Homes all motors in-parallel. The homing trajectories for the motors as they are used now should not intersect
    # with each other, so it is safe to move both assemblies at the same time.
    zaber_motors.prepare_motors()

    # Sets the motors into the mounting position. Since there should not be any previous positions, all motors should
    # be set to the default mounting position.
    zaber_motors.mount_position()

    message = "Motor Positioning: Complete."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # This section is where most manual manipulations take place, as the user needs to move the objective to the imaging
    # plane and check the quality of surgery.
    message = (
        "Position the mesoscope objective above the imaging field to asses the animal surgery and cranial window "
        "implantation quality. Exercise caution when moving HeadBar Roll and Pitch axes motors. Make sure you are "
        "satisfied with the imaging quality before proceeding further."
    )
    console.echo(message=message, level=LogLevel.WARNING)
    input("Enter anything to continue: ")

    # Generates the mesoscope positions file precursor in the raw_data folder of the managed session and forces the
    # user to update it with the current mesoscope objective positions.
    mesoscope_positions = MesoscopePositions()
    mesoscope_positions.to_yaml(file_path=Path(session_data.raw_data.mesoscope_positions_path))
    message = f"Mesoscope positions precursor file: Generated."
    console.echo(message=message, level=LogLevel.SUCCESS)

    message = (
        "Generate the cranial window screenshot and record the mesoscope objective positions in the precursor "
        "mesoscope_positions file."
    )
    console.echo(message=message, level=LogLevel.WARNING)
    input("Enter anything to continue: ")

    # Retrieves current motor positions and packages them into a ZaberPositions object.
    zaber_positions = zaber_motors.generate_position_snapshot()

    # Dumps zaber data into the raw_data folder of the new session and the persistent_data folder of the animal
    zaber_positions.to_yaml(file_path=Path(session_data.raw_data.zaber_positions_path))
    zaber_positions.to_yaml(file_path=Path(mesoscope_data.vrpc_persistent_data.zaber_positions_path))

    message = f"Zaber motor position snapshot: Saved."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # Forces the user to always have a single cranial window screenshot and does not allow proceeding until the
    # screenshot is generated.
    mesodata_path = Path(mesoscope_data.scanimagepc_data.meso_data_path)
    screenshots = [screenshot for screenshot in mesodata_path.glob("*.png")]
    while len(screenshots) != 1:
        message = (
            f"Unable to retrieve the screenshot of the cranial window and the dot-alignment from the "
            f"ScanImage PC. Specifically, expected a single .png file to be stored in the root mesoscope "
            f"data folder of the ScanImagePC, but instead found {len(screenshots)} candidates. Generate a "
            f"single screenshot of the cranial window and the dot-alignment on the ScanImagePC by "
            f"positioning them side-by-side and using 'Win + PrtSc' combination. Remove any extra "
            f"screenshots stored in the folder before proceeding."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")
        screenshots = [screenshot for screenshot in mesodata_path.glob("*.png")]

    # Moves the screenshot to the raw_data session folder
    screenshot_path: Path = screenshots[0]
    sh.move(src=screenshot_path, dst=Path(session_data.raw_data.window_screenshot_path))
    message = f"Cranial window and dot-alignment screenshot: Saved."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # Forces the user to update the mesoscope positions file with current mesoscope data.
    mesoscope_positions = MesoscopePositions.from_yaml(  # type: ignore
        file_path=Path(session_data.raw_data.mesoscope_positions_path)
    )
    while (
        mesoscope_positions.mesoscope_x == 0.0
        and mesoscope_positions.mesoscope_y == 0.0
        and mesoscope_positions.mesoscope_z == 0.0
        and mesoscope_positions.mesoscope_roll == 0.0
        and mesoscope_positions.mesoscope_fast_z == 0.0
        and mesoscope_positions.mesoscope_tip == 0.0
        and mesoscope_positions.mesoscope_tilt == 0.0
    ):
        message = (
            "Failed to verify that the mesoscope_positions.yaml file stored inside the session raw_data directory "
            "has been updated to include the mesoscope objective positions used during runtime. Manually edit the "
            "mesoscope_positions.yaml file and replace the default text under the necessary mesoscope axis position "
            "fields with coordinates displayed in the ScanImage software or the ThorLabs pad. Make sure to save the "
            "changes to the file by using 'CTRL+S' combination."
        )
        console.echo(message=message, level=LogLevel.WARNING)
        input("Enter anything to continue: ")

        # Reloads the mesoscope positions data each time to verify whether the user ahs edited the data.
        mesoscope_positions = MesoscopePositions.from_yaml(  # type: ignore
            file_path=Path(session_data.raw_data.mesoscope_positions_path)
        )

    # Dumps the updated data into the persistent_data folder of the animal
    mesoscope_positions.to_yaml(file_path=Path(mesoscope_data.vrpc_persistent_data.mesoscope_positions_path))

    message = f"Mesoscope-VR and cranial window state snapshot: Generated."
    console.echo(message=message, level=LogLevel.SUCCESS)

    message = f"Retracting the lick-port away from the animal..."
    console.echo(message=message, level=LogLevel.INFO)

    # Helps with removing the animal from the rig by retracting the lick-port in the Y-axis (moving it away from the
    # animal).
    zaber_motors.unmount_position()

    message = "Motor Positioning: Complete."
    console.echo(message=message, level=LogLevel.SUCCESS)

    # Instructs the user to remove all objects that may interfere with moving the motors.
    message = (
        "REMOVE the animal and the mesoscope objective from the VR rig. Failure to do so may HARM the animal and "
        "DAMAGE the mesoscope. This is the last manual checkpoint, once you progress past this point, the "
        "Microscope-VR system will reset Zaber motor positions and start data preprocessing."
    )
    console.echo(message=message, level=LogLevel.WARNING)
    input("Enter anything to continue: ")

    # Shuts down zaber bindings
    zaber_motors.park_position()
    zaber_motors.disconnect()

    # Terminates the face camera
    cameras.stop()

    # Stops the data logger
    logger.stop()

    # Triggers preprocessing pipeline. In this case, since there is no data to preprocess, the pipeline primarily just
    # copies the session raw_data folder to the NAS and BioHPC server.
    preprocess_session_data(session_data=session_data)

    # Ends the runtime
    message = f"Window checking runtime: Terminated."
    console.echo(message=message, level=LogLevel.SUCCESS)
